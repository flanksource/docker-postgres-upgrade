// Code generated by github.com/atombender/go-jsonschema, DO NOT EDIT.

package pkg

import (
	"encoding/json"
	"github.com/flanksource/postgres/pkg/types"
)
import "fmt"
import "reflect"
import "regexp"

// Database connection configuration for PgBouncer
type DatabaseConfig struct {
	// Query to run on new connections
	ConnectQuery *string `json:"connect_query,omitempty" yaml:"connect_query,omitempty" mapstructure:"connect_query,omitempty"`

	// Database name
	Dbname *string `json:"dbname,omitempty" yaml:"dbname,omitempty" mapstructure:"dbname,omitempty"`

	// Database host
	Host string `json:"host,omitempty" yaml:"host,omitempty" mapstructure:"host,omitempty"`

	// Database password
	Password *string `json:"password,omitempty" yaml:"password,omitempty" mapstructure:"password,omitempty"`

	// Pool size for this database
	PoolSize *int `json:"pool_size,omitempty" yaml:"pool_size,omitempty" mapstructure:"pool_size,omitempty"`

	// Database port
	Port int `json:"port,omitempty" yaml:"port,omitempty" mapstructure:"port,omitempty"`

	// Database user
	User *string `json:"user,omitempty" yaml:"user,omitempty" mapstructure:"user,omitempty"`
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *DatabaseConfig) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain DatabaseConfig
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["host"]; !ok || v == nil {
		plain.Host = "localhost"
	}
	if plain.PoolSize != nil && 1 > *plain.PoolSize {
		return fmt.Errorf("field %s: must be >= %v", "pool_size", 1)
	}
	if v, ok := raw["port"]; !ok || v == nil {
		plain.Port = 5432.0
	}
	if 65535 < plain.Port {
		return fmt.Errorf("field %s: must be <= %v", "port", 65535)
	}
	if 1 > plain.Port {
		return fmt.Errorf("field %s: must be >= %v", "port", 1)
	}
	*j = DatabaseConfig(plain)
	return nil
}

// PGAudit extension configuration for PostgreSQL audit logging
type PGAuditConf struct {
	// Specifies whether audit logging should be filtered using role-based access
	// control
	FilterUsingRole PGAuditConfFilterUsingRole `json:"filter_using_role,omitempty" yaml:"filter_using_role,omitempty" mapstructure:"filter_using_role,omitempty"`

	// Specifies which classes of statements will be logged by session audit logging
	Log PGAuditConfLog `json:"log,omitempty" yaml:"log,omitempty" mapstructure:"log,omitempty"`

	// Specifies that session logging should be enabled in the case where all
	// relations in a statement are in pg_catalog
	LogCatalog PGAuditConfLogCatalog `json:"log_catalog,omitempty" yaml:"log_catalog,omitempty" mapstructure:"log_catalog,omitempty"`

	// Specifies whether log messages will be visible to a client process
	LogClient PGAuditConfLogClient `json:"log_client,omitempty" yaml:"log_client,omitempty" mapstructure:"log_client,omitempty"`

	// Specifies the log level that will be used for log entries
	LogLevel PGAuditConfLogLevel `json:"log_level,omitempty" yaml:"log_level,omitempty" mapstructure:"log_level,omitempty"`

	// Specifies that audit logging should include the parameters that were passed
	// with the statement
	LogParameter PGAuditConfLogParameter `json:"log_parameter,omitempty" yaml:"log_parameter,omitempty" mapstructure:"log_parameter,omitempty"`

	// Sets the maximum size of a parameter value that will be logged
	LogParameterMaxSize string `json:"log_parameter_max_size,omitempty" yaml:"log_parameter_max_size,omitempty" mapstructure:"log_parameter_max_size,omitempty"`

	// Specifies whether session audit logging should create a separate log entry for
	// each relation referenced in a SELECT or DML statement
	LogRelation PGAuditConfLogRelation `json:"log_relation,omitempty" yaml:"log_relation,omitempty" mapstructure:"log_relation,omitempty"`

	// Specifies whether logging will include the statement text and parameters (if
	// enabled)
	LogStatement PGAuditConfLogStatement `json:"log_statement,omitempty" yaml:"log_statement,omitempty" mapstructure:"log_statement,omitempty"`

	// Specifies whether logging will include the statement text and parameters (if
	// enabled) with the first log entry for a statement/substatement combination or
	// with every log entry
	LogStatementOnce PGAuditConfLogStatementOnce `json:"log_statement_once,omitempty" yaml:"log_statement_once,omitempty" mapstructure:"log_statement_once,omitempty"`

	// Sets the maximum stack depth for audit logging to prevent infinite recursion
	MaxStackDepth *types.Size `json:"max_stack_depth,omitempty" yaml:"max_stack_depth,omitempty" mapstructure:"max_stack_depth,omitempty"`

	// Specifies which classes of statements will be logged by object audit logging
	ObjectLog PGAuditConfObjectLog `json:"object_log,omitempty" yaml:"object_log,omitempty" mapstructure:"object_log,omitempty"`

	// Specifies that object logging should be enabled in the case where all relations
	// in a statement are in pg_catalog
	ObjectLogCatalog PGAuditConfObjectLogCatalog `json:"object_log_catalog,omitempty" yaml:"object_log_catalog,omitempty" mapstructure:"object_log_catalog,omitempty"`

	// Specifies the master role to use for object audit logging
	Role *string `json:"role,omitempty" yaml:"role,omitempty" mapstructure:"role,omitempty"`

	// Specifies whether the statement name, if provided, should be included in the
	// session log
	SessionLogStatementName PGAuditConfSessionLogStatementName `json:"session_log_statement_name,omitempty" yaml:"session_log_statement_name,omitempty" mapstructure:"session_log_statement_name,omitempty"`
}

type PGAuditConfFilterUsingRole string

const PGAuditConfFilterUsingRoleOff PGAuditConfFilterUsingRole = "off"
const PGAuditConfFilterUsingRoleOn PGAuditConfFilterUsingRole = "on"

var enumValues_PGAuditConfFilterUsingRole = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfFilterUsingRole) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfFilterUsingRole {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfFilterUsingRole, v)
	}
	*j = PGAuditConfFilterUsingRole(v)
	return nil
}

type PGAuditConfLog string

const PGAuditConfLogAll PGAuditConfLog = "all"

type PGAuditConfLogCatalog string

const PGAuditConfLogCatalogOff PGAuditConfLogCatalog = "off"
const PGAuditConfLogCatalogOn PGAuditConfLogCatalog = "on"

var enumValues_PGAuditConfLogCatalog = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogCatalog) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogCatalog {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogCatalog, v)
	}
	*j = PGAuditConfLogCatalog(v)
	return nil
}

type PGAuditConfLogClient string

const PGAuditConfLogClientOff PGAuditConfLogClient = "off"
const PGAuditConfLogClientOn PGAuditConfLogClient = "on"

var enumValues_PGAuditConfLogClient = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogClient) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogClient {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogClient, v)
	}
	*j = PGAuditConfLogClient(v)
	return nil
}

const PGAuditConfLogDdl PGAuditConfLog = "ddl"
const PGAuditConfLogFunction PGAuditConfLog = "function"

type PGAuditConfLogLevel string

const PGAuditConfLogLevelDebug1 PGAuditConfLogLevel = "debug1"
const PGAuditConfLogLevelDebug2 PGAuditConfLogLevel = "debug2"
const PGAuditConfLogLevelDebug3 PGAuditConfLogLevel = "debug3"
const PGAuditConfLogLevelDebug4 PGAuditConfLogLevel = "debug4"
const PGAuditConfLogLevelDebug5 PGAuditConfLogLevel = "debug5"
const PGAuditConfLogLevelInfo PGAuditConfLogLevel = "info"
const PGAuditConfLogLevelLog PGAuditConfLogLevel = "log"
const PGAuditConfLogLevelNotice PGAuditConfLogLevel = "notice"
const PGAuditConfLogLevelWarning PGAuditConfLogLevel = "warning"

var enumValues_PGAuditConfLogLevel = []interface{}{
	"debug5",
	"debug4",
	"debug3",
	"debug2",
	"debug1",
	"info",
	"notice",
	"warning",
	"log",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogLevel) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogLevel {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogLevel, v)
	}
	*j = PGAuditConfLogLevel(v)
	return nil
}

const PGAuditConfLogMisc PGAuditConfLog = "misc"
const PGAuditConfLogMiscSet PGAuditConfLog = "misc_set"
const PGAuditConfLogNone PGAuditConfLog = "none"

type PGAuditConfLogParameter string

const PGAuditConfLogParameterOff PGAuditConfLogParameter = "off"
const PGAuditConfLogParameterOn PGAuditConfLogParameter = "on"

var enumValues_PGAuditConfLogParameter = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogParameter) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogParameter {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogParameter, v)
	}
	*j = PGAuditConfLogParameter(v)
	return nil
}

const PGAuditConfLogRead PGAuditConfLog = "read"

type PGAuditConfLogRelation string

const PGAuditConfLogRelationOff PGAuditConfLogRelation = "off"
const PGAuditConfLogRelationOn PGAuditConfLogRelation = "on"

var enumValues_PGAuditConfLogRelation = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogRelation) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogRelation {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogRelation, v)
	}
	*j = PGAuditConfLogRelation(v)
	return nil
}

const PGAuditConfLogRole PGAuditConfLog = "role"

type PGAuditConfLogStatement string

const PGAuditConfLogStatementOff PGAuditConfLogStatement = "off"
const PGAuditConfLogStatementOn PGAuditConfLogStatement = "on"

type PGAuditConfLogStatementOnce string

const PGAuditConfLogStatementOnceOff PGAuditConfLogStatementOnce = "off"
const PGAuditConfLogStatementOnceOn PGAuditConfLogStatementOnce = "on"

var enumValues_PGAuditConfLogStatementOnce = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogStatementOnce) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogStatementOnce {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogStatementOnce, v)
	}
	*j = PGAuditConfLogStatementOnce(v)
	return nil
}

var enumValues_PGAuditConfLogStatement = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLogStatement) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLogStatement {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLogStatement, v)
	}
	*j = PGAuditConfLogStatement(v)
	return nil
}

const PGAuditConfLogWrite PGAuditConfLog = "write"

var enumValues_PGAuditConfLog = []interface{}{
	"none",
	"read",
	"write",
	"function",
	"role",
	"ddl",
	"misc",
	"misc_set",
	"all",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfLog) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfLog {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfLog, v)
	}
	*j = PGAuditConfLog(v)
	return nil
}

type PGAuditConfObjectLog string

const PGAuditConfObjectLogAll PGAuditConfObjectLog = "all"

type PGAuditConfObjectLogCatalog string

const PGAuditConfObjectLogCatalogOff PGAuditConfObjectLogCatalog = "off"
const PGAuditConfObjectLogCatalogOn PGAuditConfObjectLogCatalog = "on"

var enumValues_PGAuditConfObjectLogCatalog = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfObjectLogCatalog) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfObjectLogCatalog {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfObjectLogCatalog, v)
	}
	*j = PGAuditConfObjectLogCatalog(v)
	return nil
}

const PGAuditConfObjectLogDdl PGAuditConfObjectLog = "ddl"
const PGAuditConfObjectLogFunction PGAuditConfObjectLog = "function"
const PGAuditConfObjectLogMisc PGAuditConfObjectLog = "misc"
const PGAuditConfObjectLogMiscSet PGAuditConfObjectLog = "misc_set"
const PGAuditConfObjectLogNone PGAuditConfObjectLog = "none"
const PGAuditConfObjectLogRead PGAuditConfObjectLog = "read"
const PGAuditConfObjectLogRole PGAuditConfObjectLog = "role"
const PGAuditConfObjectLogWrite PGAuditConfObjectLog = "write"

var enumValues_PGAuditConfObjectLog = []interface{}{
	"none",
	"read",
	"write",
	"function",
	"role",
	"ddl",
	"misc",
	"misc_set",
	"all",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfObjectLog) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfObjectLog {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfObjectLog, v)
	}
	*j = PGAuditConfObjectLog(v)
	return nil
}

type PGAuditConfSessionLogStatementName string

const PGAuditConfSessionLogStatementNameOff PGAuditConfSessionLogStatementName = "off"
const PGAuditConfSessionLogStatementNameOn PGAuditConfSessionLogStatementName = "on"

var enumValues_PGAuditConfSessionLogStatementName = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConfSessionLogStatementName) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PGAuditConfSessionLogStatementName {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PGAuditConfSessionLogStatementName, v)
	}
	*j = PGAuditConfSessionLogStatementName(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PGAuditConf) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain PGAuditConf
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["filter_using_role"]; !ok || v == nil {
		plain.FilterUsingRole = "off"
	}
	if v, ok := raw["log"]; !ok || v == nil {
		plain.Log = "none"
	}
	if v, ok := raw["log_catalog"]; !ok || v == nil {
		plain.LogCatalog = "on"
	}
	if v, ok := raw["log_client"]; !ok || v == nil {
		plain.LogClient = "off"
	}
	if v, ok := raw["log_level"]; !ok || v == nil {
		plain.LogLevel = "log"
	}
	if v, ok := raw["log_parameter"]; !ok || v == nil {
		plain.LogParameter = "off"
	}
	if v, ok := raw["log_parameter_max_size"]; !ok || v == nil {
		plain.LogParameterMaxSize = "0"
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B?$`, string(plain.LogParameterMaxSize)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "LogParameterMaxSize", `^[0-9]+[kMGT]?B?$`)
	}
	if v, ok := raw["log_relation"]; !ok || v == nil {
		plain.LogRelation = "off"
	}
	if v, ok := raw["log_statement"]; !ok || v == nil {
		plain.LogStatement = "on"
	}
	if v, ok := raw["log_statement_once"]; !ok || v == nil {
		plain.LogStatementOnce = "off"
	}
	if plain.MaxStackDepth != nil {
		if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B?$`, plain.MaxStackDepth.String()); !matched {
			return fmt.Errorf("field %s pattern match: must match %s", "MaxStackDepth", `^[0-9]+[kMGT]?B?$`)
		}
	}
	if v, ok := raw["object_log"]; !ok || v == nil {
		plain.ObjectLog = "none"
	}
	if v, ok := raw["object_log_catalog"]; !ok || v == nil {
		plain.ObjectLogCatalog = "on"
	}
	if v, ok := raw["session_log_statement_name"]; !ok || v == nil {
		plain.SessionLogStatementName = "off"
	}
	*j = PGAuditConf(plain)
	return nil
}

// PgBouncer connection pooler configuration
type PgBouncerConf struct {
	// Administrative password for PgBouncer
	AdminPassword *string `json:"admin_password,omitempty" yaml:"admin_password,omitempty" mapstructure:"admin_password,omitempty"`

	// Administrative user for PgBouncer
	AdminUser *string `json:"admin_user,omitempty" yaml:"admin_user,omitempty" mapstructure:"admin_user,omitempty"`

	// Path to authentication file
	AuthFile string `json:"auth_file,omitempty" yaml:"auth_file,omitempty" mapstructure:"auth_file,omitempty"`

	// Query to authenticate users
	AuthQuery string `json:"auth_query,omitempty" yaml:"auth_query,omitempty" mapstructure:"auth_query,omitempty"`

	// Authentication type for PgBouncer
	AuthType PgBouncerConfAuthType `json:"auth_type,omitempty" yaml:"auth_type,omitempty" mapstructure:"auth_type,omitempty"`

	// Maximum idle time for client connections
	ClientIdleTimeout string `json:"client_idle_timeout,omitempty" yaml:"client_idle_timeout,omitempty" mapstructure:"client_idle_timeout,omitempty"`

	// Database connection configurations
	Databases map[string]DatabaseConfig `json:"databases,omitempty" yaml:"databases,omitempty" mapstructure:"databases,omitempty"`

	// Default pool size for databases
	DefaultPoolSize int `json:"default_pool_size,omitempty" yaml:"default_pool_size,omitempty" mapstructure:"default_pool_size,omitempty"`

	// Specifies the address to listen on
	ListenAddress string `json:"listen_address,omitempty" yaml:"listen_address,omitempty" mapstructure:"listen_address,omitempty"`

	// Specifies the port to listen on
	ListenPort int `json:"listen_port,omitempty" yaml:"listen_port,omitempty" mapstructure:"listen_port,omitempty"`

	// Maximum number of client connections allowed
	MaxClientConn int `json:"max_client_conn,omitempty" yaml:"max_client_conn,omitempty" mapstructure:"max_client_conn,omitempty"`

	// Minimum pool size
	MinPoolSize int `json:"min_pool_size,omitempty" yaml:"min_pool_size,omitempty" mapstructure:"min_pool_size,omitempty"`

	// Pooling mode to use
	PoolMode PgBouncerConfPoolMode `json:"pool_mode,omitempty" yaml:"pool_mode,omitempty" mapstructure:"pool_mode,omitempty"`

	// Query timeout
	QueryTimeout string `json:"query_timeout,omitempty" yaml:"query_timeout,omitempty" mapstructure:"query_timeout,omitempty"`

	// Reserved pool size
	ReservePoolSize *int `json:"reserve_pool_size,omitempty" yaml:"reserve_pool_size,omitempty" mapstructure:"reserve_pool_size,omitempty"`

	// Maximum idle time for server connections
	ServerIdleTimeout string `json:"server_idle_timeout,omitempty" yaml:"server_idle_timeout,omitempty" mapstructure:"server_idle_timeout,omitempty"`

	// Maximum lifetime of a server connection
	ServerLifetime string `json:"server_lifetime,omitempty" yaml:"server_lifetime,omitempty" mapstructure:"server_lifetime,omitempty"`

	// Query to run on server connection before returning to pool
	ServerResetQuery string `json:"server_reset_query,omitempty" yaml:"server_reset_query,omitempty" mapstructure:"server_reset_query,omitempty"`
}

type PgBouncerConfAuthType string

const PgBouncerConfAuthTypeAny PgBouncerConfAuthType = "any"
const PgBouncerConfAuthTypeCert PgBouncerConfAuthType = "cert"
const PgBouncerConfAuthTypeHba PgBouncerConfAuthType = "hba"
const PgBouncerConfAuthTypeMd5 PgBouncerConfAuthType = "md5"
const PgBouncerConfAuthTypePam PgBouncerConfAuthType = "pam"
const PgBouncerConfAuthTypePlain PgBouncerConfAuthType = "plain"
const PgBouncerConfAuthTypeScramSha256 PgBouncerConfAuthType = "scram-sha-256"
const PgBouncerConfAuthTypeTrust PgBouncerConfAuthType = "trust"

var enumValues_PgBouncerConfAuthType = []interface{}{
	"any",
	"trust",
	"plain",
	"md5",
	"scram-sha-256",
	"cert",
	"hba",
	"pam",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgBouncerConfAuthType) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PgBouncerConfAuthType {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PgBouncerConfAuthType, v)
	}
	*j = PgBouncerConfAuthType(v)
	return nil
}

type PgBouncerConfPoolMode string

const PgBouncerConfPoolModeSession PgBouncerConfPoolMode = "session"
const PgBouncerConfPoolModeStatement PgBouncerConfPoolMode = "statement"
const PgBouncerConfPoolModeTransaction PgBouncerConfPoolMode = "transaction"

var enumValues_PgBouncerConfPoolMode = []interface{}{
	"session",
	"transaction",
	"statement",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgBouncerConfPoolMode) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PgBouncerConfPoolMode {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PgBouncerConfPoolMode, v)
	}
	*j = PgBouncerConfPoolMode(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgBouncerConf) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain PgBouncerConf
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["auth_file"]; !ok || v == nil {
		plain.AuthFile = "userlist.txt"
	}
	if v, ok := raw["auth_query"]; !ok || v == nil {
		plain.AuthQuery = "SELECT usename, passwd FROM pg_shadow WHERE usename=$1"
	}
	if v, ok := raw["auth_type"]; !ok || v == nil {
		plain.AuthType = "md5"
	}
	if v, ok := raw["client_idle_timeout"]; !ok || v == nil {
		plain.ClientIdleTimeout = "0"
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.ClientIdleTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "ClientIdleTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["default_pool_size"]; !ok || v == nil {
		plain.DefaultPoolSize = 25.0
	}
	if 1 > plain.DefaultPoolSize {
		return fmt.Errorf("field %s: must be >= %v", "default_pool_size", 1)
	}
	if v, ok := raw["listen_address"]; !ok || v == nil {
		plain.ListenAddress = "0.0.0.0"
	}
	if v, ok := raw["listen_port"]; !ok || v == nil {
		plain.ListenPort = 6432.0
	}
	if 65535 < plain.ListenPort {
		return fmt.Errorf("field %s: must be <= %v", "listen_port", 65535)
	}
	if 1 > plain.ListenPort {
		return fmt.Errorf("field %s: must be >= %v", "listen_port", 1)
	}
	if v, ok := raw["max_client_conn"]; !ok || v == nil {
		plain.MaxClientConn = 100.0
	}
	if 1 > plain.MaxClientConn {
		return fmt.Errorf("field %s: must be >= %v", "max_client_conn", 1)
	}
	if v, ok := raw["min_pool_size"]; !ok || v == nil {
		plain.MinPoolSize = 0.0
	}
	if 0 > plain.MinPoolSize {
		return fmt.Errorf("field %s: must be >= %v", "min_pool_size", 0)
	}
	if v, ok := raw["pool_mode"]; !ok || v == nil {
		plain.PoolMode = "transaction"
	}
	if v, ok := raw["query_timeout"]; !ok || v == nil {
		plain.QueryTimeout = "0"
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.QueryTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "QueryTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if plain.ReservePoolSize != nil && 0 > *plain.ReservePoolSize {
		return fmt.Errorf("field %s: must be >= %v", "reserve_pool_size", 0)
	}
	if v, ok := raw["server_idle_timeout"]; !ok || v == nil {
		plain.ServerIdleTimeout = "600s"
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.ServerIdleTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "ServerIdleTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["server_lifetime"]; !ok || v == nil {
		plain.ServerLifetime = "3600s"
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.ServerLifetime)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "ServerLifetime", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["server_reset_query"]; !ok || v == nil {
		plain.ServerResetQuery = "DISCARD ALL"
	}
	*j = PgBouncerConf(plain)
	return nil
}

// PostgreSQL host-based authentication configuration
type PgHBAConf struct {
	// List of host-based authentication rules
	Rules []PgHBAConfRulesElem `json:"rules,omitempty" yaml:"rules,omitempty" mapstructure:"rules,omitempty"`
}

type PgHBAConfRulesElem struct {
	// Client IP address, hostname, or CIDR range
	Address *string `json:"address,omitempty" yaml:"address,omitempty" mapstructure:"address,omitempty"`

	// Database name or 'all'
	Database string `json:"database" yaml:"database" mapstructure:"database"`

	// Authentication method
	Method PgHBAConfRulesElemMethod `json:"method" yaml:"method" mapstructure:"method"`

	// Additional authentication options
	Options map[string]string `json:"options,omitempty" yaml:"options,omitempty" mapstructure:"options,omitempty"`

	// Connection type
	Type PgHBAConfRulesElemType `json:"type" yaml:"type" mapstructure:"type"`

	// Username or 'all'
	User string `json:"user" yaml:"user" mapstructure:"user"`
}

type PgHBAConfRulesElemMethod string

const PgHBAConfRulesElemMethodBsd PgHBAConfRulesElemMethod = "bsd"
const PgHBAConfRulesElemMethodCert PgHBAConfRulesElemMethod = "cert"
const PgHBAConfRulesElemMethodGss PgHBAConfRulesElemMethod = "gss"
const PgHBAConfRulesElemMethodIdent PgHBAConfRulesElemMethod = "ident"
const PgHBAConfRulesElemMethodLdap PgHBAConfRulesElemMethod = "ldap"
const PgHBAConfRulesElemMethodMd5 PgHBAConfRulesElemMethod = "md5"
const PgHBAConfRulesElemMethodPam PgHBAConfRulesElemMethod = "pam"
const PgHBAConfRulesElemMethodPassword PgHBAConfRulesElemMethod = "password"
const PgHBAConfRulesElemMethodPeer PgHBAConfRulesElemMethod = "peer"
const PgHBAConfRulesElemMethodRadius PgHBAConfRulesElemMethod = "radius"
const PgHBAConfRulesElemMethodReject PgHBAConfRulesElemMethod = "reject"
const PgHBAConfRulesElemMethodScramSha256 PgHBAConfRulesElemMethod = "scram-sha-256"
const PgHBAConfRulesElemMethodSspi PgHBAConfRulesElemMethod = "sspi"
const PgHBAConfRulesElemMethodTrust PgHBAConfRulesElemMethod = "trust"

var enumValues_PgHBAConfRulesElemMethod = []interface{}{
	"trust",
	"reject",
	"md5",
	"password",
	"scram-sha-256",
	"gss",
	"sspi",
	"ident",
	"peer",
	"ldap",
	"radius",
	"cert",
	"pam",
	"bsd",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgHBAConfRulesElemMethod) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PgHBAConfRulesElemMethod {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PgHBAConfRulesElemMethod, v)
	}
	*j = PgHBAConfRulesElemMethod(v)
	return nil
}

type PgHBAConfRulesElemType string

const PgHBAConfRulesElemTypeHost PgHBAConfRulesElemType = "host"
const PgHBAConfRulesElemTypeHostgssenc PgHBAConfRulesElemType = "hostgssenc"
const PgHBAConfRulesElemTypeHostnogssenc PgHBAConfRulesElemType = "hostnogssenc"
const PgHBAConfRulesElemTypeHostnossl PgHBAConfRulesElemType = "hostnossl"
const PgHBAConfRulesElemTypeHostssl PgHBAConfRulesElemType = "hostssl"
const PgHBAConfRulesElemTypeLocal PgHBAConfRulesElemType = "local"

var enumValues_PgHBAConfRulesElemType = []interface{}{
	"local",
	"host",
	"hostssl",
	"hostnossl",
	"hostgssenc",
	"hostnogssenc",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgHBAConfRulesElemType) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PgHBAConfRulesElemType {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PgHBAConfRulesElemType, v)
	}
	*j = PgHBAConfRulesElemType(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PgHBAConfRulesElem) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	if _, ok := raw["method"]; raw != nil && !ok {
		return fmt.Errorf("field method in PgHBAConfRulesElem: required")
	}
	if _, ok := raw["type"]; raw != nil && !ok {
		return fmt.Errorf("field type in PgHBAConfRulesElem: required")
	}
	type Plain PgHBAConfRulesElem
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["database"]; !ok || v == nil {
		plain.Database = "all"
	}
	if v, ok := raw["user"]; !ok || v == nil {
		plain.User = "all"
	}
	*j = PgHBAConfRulesElem(plain)
	return nil
}

type PgconfigSchemaJson struct {
	// Pgaudit corresponds to the JSON schema field "pgaudit".
	Pgaudit *PGAuditConf `json:"pgaudit,omitempty" yaml:"pgaudit,omitempty" mapstructure:"pgaudit,omitempty"`

	// Pgbouncer corresponds to the JSON schema field "pgbouncer".
	Pgbouncer *PgBouncerConf `json:"pgbouncer,omitempty" yaml:"pgbouncer,omitempty" mapstructure:"pgbouncer,omitempty"`

	// Pghba corresponds to the JSON schema field "pghba".
	Pghba *PgHBAConf `json:"pghba,omitempty" yaml:"pghba,omitempty" mapstructure:"pghba,omitempty"`

	// Postgres corresponds to the JSON schema field "postgres".
	Postgres *PostgresConf `json:"postgres,omitempty" yaml:"postgres,omitempty" mapstructure:"postgres,omitempty"`

	// Postgrest corresponds to the JSON schema field "postgrest".
	Postgrest *PostgrestConf `json:"postgrest,omitempty" yaml:"postgrest,omitempty" mapstructure:"postgrest,omitempty"`

	// Walg corresponds to the JSON schema field "walg".
	Walg *WalgConf `json:"walg,omitempty" yaml:"walg,omitempty" mapstructure:"walg,omitempty"`
}

// Main PostgreSQL server configuration
type PostgresConf struct {
	// Sets the display format for date and time values. Also controls interpretation
	// of ambiguous date inputs.
	DateStyle string `json:"DateStyle,omitempty" yaml:"DateStyle,omitempty" mapstructure:"DateStyle,omitempty"`

	// Sets the display format for interval values.
	IntervalStyle string `json:"IntervalStyle,omitempty" yaml:"IntervalStyle,omitempty" mapstructure:"IntervalStyle,omitempty"`

	// Sets the time zone for displaying and interpreting time stamps.
	TimeZone string `json:"TimeZone,omitempty" yaml:"TimeZone,omitempty" mapstructure:"TimeZone,omitempty"`

	// Allows running the ALTER SYSTEM command. Can be set to off for environments
	// where global configuration changes should be made using a different method.
	AllowAlterSystem bool `json:"allow_alter_system,omitempty" yaml:"allow_alter_system,omitempty" mapstructure:"allow_alter_system,omitempty"`

	// Sets the shell command that will be executed at every restart point.
	ArchiveCleanupCommand *string `json:"archive_cleanup_command,omitempty" yaml:"archive_cleanup_command,omitempty" mapstructure:"archive_cleanup_command,omitempty"`

	// Sets the shell command that will be called to archive a WAL file. This is used
	// only if "archive_library" is not set.
	ArchiveCommand *string `json:"archive_command,omitempty" yaml:"archive_command,omitempty" mapstructure:"archive_command,omitempty"`

	// Sets the library that will be called to archive a WAL file. An empty string
	// indicates that "archive_command" should be used.
	ArchiveLibrary *string `json:"archive_library,omitempty" yaml:"archive_library,omitempty" mapstructure:"archive_library,omitempty"`

	// Allows archiving of WAL files using "archive_command".
	ArchiveMode PostgresConfArchiveMode `json:"archive_mode,omitempty" yaml:"archive_mode,omitempty" mapstructure:"archive_mode,omitempty"`

	// Sets the amount of time to wait before forcing a switch to the next WAL file.
	ArchiveTimeout int `json:"archive_timeout,omitempty" yaml:"archive_timeout,omitempty" mapstructure:"archive_timeout,omitempty"`

	// Enable input of NULL elements in arrays. When turned on, unquoted NULL in an
	// array input value means a null value; otherwise it is taken literally.
	ArrayNulls bool `json:"array_nulls,omitempty" yaml:"array_nulls,omitempty" mapstructure:"array_nulls,omitempty"`

	// Sets the maximum allowed time to complete client authentication.
	AuthenticationTimeout *types.Duration `json:"authentication_timeout,omitempty" yaml:"authentication_timeout,omitempty" mapstructure:"authentication_timeout,omitempty"`

	// Starts the autovacuum subprocess.
	Autovacuum bool `json:"autovacuum,omitempty" yaml:"autovacuum,omitempty" mapstructure:"autovacuum,omitempty"`

	// Number of tuple inserts, updates, or deletes prior to analyze as a fraction of
	// reltuples.
	AutovacuumAnalyzeScaleFactor float64 `json:"autovacuum_analyze_scale_factor,omitempty" yaml:"autovacuum_analyze_scale_factor,omitempty" mapstructure:"autovacuum_analyze_scale_factor,omitempty"`

	// Minimum number of tuple inserts, updates, or deletes prior to analyze.
	AutovacuumAnalyzeThreshold int `json:"autovacuum_analyze_threshold,omitempty" yaml:"autovacuum_analyze_threshold,omitempty" mapstructure:"autovacuum_analyze_threshold,omitempty"`

	// Age at which to autovacuum a table to prevent transaction ID wraparound.
	AutovacuumFreezeMaxAge int `json:"autovacuum_freeze_max_age,omitempty" yaml:"autovacuum_freeze_max_age,omitempty" mapstructure:"autovacuum_freeze_max_age,omitempty"`

	// Sets the maximum number of simultaneously running autovacuum worker processes.
	AutovacuumMaxWorkers int `json:"autovacuum_max_workers,omitempty" yaml:"autovacuum_max_workers,omitempty" mapstructure:"autovacuum_max_workers,omitempty"`

	// Multixact age at which to autovacuum a table to prevent multixact wraparound.
	AutovacuumMultixactFreezeMaxAge int `json:"autovacuum_multixact_freeze_max_age,omitempty" yaml:"autovacuum_multixact_freeze_max_age,omitempty" mapstructure:"autovacuum_multixact_freeze_max_age,omitempty"`

	// Time to sleep between autovacuum runs.
	AutovacuumNaptime int `json:"autovacuum_naptime,omitempty" yaml:"autovacuum_naptime,omitempty" mapstructure:"autovacuum_naptime,omitempty"`

	// Vacuum cost delay in milliseconds, for autovacuum.
	AutovacuumVacuumCostDelay *types.Duration `json:"autovacuum_vacuum_cost_delay,omitempty" yaml:"autovacuum_vacuum_cost_delay,omitempty" mapstructure:"autovacuum_vacuum_cost_delay,omitempty"`

	// Vacuum cost amount available before napping, for autovacuum.
	AutovacuumVacuumCostLimit int `json:"autovacuum_vacuum_cost_limit,omitempty" yaml:"autovacuum_vacuum_cost_limit,omitempty" mapstructure:"autovacuum_vacuum_cost_limit,omitempty"`

	// Number of tuple inserts prior to vacuum as a fraction of reltuples.
	AutovacuumVacuumInsertScaleFactor float64 `json:"autovacuum_vacuum_insert_scale_factor,omitempty" yaml:"autovacuum_vacuum_insert_scale_factor,omitempty" mapstructure:"autovacuum_vacuum_insert_scale_factor,omitempty"`

	// Minimum number of tuple inserts prior to vacuum, or -1 to disable insert
	// vacuums.
	AutovacuumVacuumInsertThreshold int `json:"autovacuum_vacuum_insert_threshold,omitempty" yaml:"autovacuum_vacuum_insert_threshold,omitempty" mapstructure:"autovacuum_vacuum_insert_threshold,omitempty"`

	// Number of tuple updates or deletes prior to vacuum as a fraction of reltuples.
	AutovacuumVacuumScaleFactor float64 `json:"autovacuum_vacuum_scale_factor,omitempty" yaml:"autovacuum_vacuum_scale_factor,omitempty" mapstructure:"autovacuum_vacuum_scale_factor,omitempty"`

	// Minimum number of tuple updates or deletes prior to vacuum.
	AutovacuumVacuumThreshold int `json:"autovacuum_vacuum_threshold,omitempty" yaml:"autovacuum_vacuum_threshold,omitempty" mapstructure:"autovacuum_vacuum_threshold,omitempty"`

	// Sets the maximum memory to be used by each autovacuum worker process.
	AutovacuumWorkMem *types.Size `json:"autovacuum_work_mem,omitempty" yaml:"autovacuum_work_mem,omitempty" mapstructure:"autovacuum_work_mem,omitempty"`

	// Number of pages after which previously performed writes are flushed to disk.
	BackendFlushAfter int `json:"backend_flush_after,omitempty" yaml:"backend_flush_after,omitempty" mapstructure:"backend_flush_after,omitempty"`

	// Sets whether "\'" is allowed in string literals.
	BackslashQuote string `json:"backslash_quote,omitempty" yaml:"backslash_quote,omitempty" mapstructure:"backslash_quote,omitempty"`

	// Background writer sleep time between rounds.
	BgwriterDelay int `json:"bgwriter_delay,omitempty" yaml:"bgwriter_delay,omitempty" mapstructure:"bgwriter_delay,omitempty"`

	// Number of pages after which previously performed writes are flushed to disk.
	BgwriterFlushAfter int `json:"bgwriter_flush_after,omitempty" yaml:"bgwriter_flush_after,omitempty" mapstructure:"bgwriter_flush_after,omitempty"`

	// Background writer maximum number of LRU pages to flush per round.
	BgwriterLruMaxpages int `json:"bgwriter_lru_maxpages,omitempty" yaml:"bgwriter_lru_maxpages,omitempty" mapstructure:"bgwriter_lru_maxpages,omitempty"`

	// Multiple of the average buffer usage to free per round.
	BgwriterLruMultiplier *types.Size `json:"bgwriter_lru_multiplier,omitempty" yaml:"bgwriter_lru_multiplier,omitempty" mapstructure:"bgwriter_lru_multiplier,omitempty"`

	// Enables advertising the server via Bonjour.
	Bonjour bool `json:"bonjour,omitempty" yaml:"bonjour,omitempty" mapstructure:"bonjour,omitempty"`

	// Sets the Bonjour service name.
	BonjourName *string `json:"bonjour_name,omitempty" yaml:"bonjour_name,omitempty" mapstructure:"bonjour_name,omitempty"`

	// Sets the output format for bytea.
	ByteaOutput string `json:"bytea_output,omitempty" yaml:"bytea_output,omitempty" mapstructure:"bytea_output,omitempty"`

	// Check routine bodies during CREATE FUNCTION and CREATE PROCEDURE.
	CheckFunctionBodies bool `json:"check_function_bodies,omitempty" yaml:"check_function_bodies,omitempty" mapstructure:"check_function_bodies,omitempty"`

	// Time spent flushing dirty buffers during checkpoint, as fraction of checkpoint
	// interval.
	CheckpointCompletionTarget *types.Size `json:"checkpoint_completion_target,omitempty" yaml:"checkpoint_completion_target,omitempty" mapstructure:"checkpoint_completion_target,omitempty"`

	// Number of pages after which previously performed writes are flushed to disk.
	CheckpointFlushAfter int `json:"checkpoint_flush_after,omitempty" yaml:"checkpoint_flush_after,omitempty" mapstructure:"checkpoint_flush_after,omitempty"`

	// Sets the maximum time between automatic WAL checkpoints.
	CheckpointTimeout *types.Duration `json:"checkpoint_timeout,omitempty" yaml:"checkpoint_timeout,omitempty" mapstructure:"checkpoint_timeout,omitempty"`

	// Sets the maximum time before warning if checkpoints triggered by WAL volume
	// happen too frequently. Write a message to the server log if checkpoints caused
	// by the filling of WAL segment files happen more frequently than this amount of
	// time. Zero turns off the warning.
	CheckpointWarning int `json:"checkpoint_warning,omitempty" yaml:"checkpoint_warning,omitempty" mapstructure:"checkpoint_warning,omitempty"`

	// Sets the time interval between checks for disconnection while running queries.
	ClientConnectionCheckInterval int `json:"client_connection_check_interval,omitempty" yaml:"client_connection_check_interval,omitempty" mapstructure:"client_connection_check_interval,omitempty"`

	// Sets the client's character set encoding.
	ClientEncoding string `json:"client_encoding,omitempty" yaml:"client_encoding,omitempty" mapstructure:"client_encoding,omitempty"`

	// Sets the message levels that are sent to the client. Each level includes all
	// the levels that follow it. The later the level, the fewer messages are sent.
	ClientMinMessages PostgresConfClientMinMessages `json:"client_min_messages,omitempty" yaml:"client_min_messages,omitempty" mapstructure:"client_min_messages,omitempty"`

	// Sets the name of the cluster, which is included in the process title.
	ClusterName *string `json:"cluster_name,omitempty" yaml:"cluster_name,omitempty" mapstructure:"cluster_name,omitempty"`

	// Sets the delay in microseconds between transaction commit and flushing WAL to
	// disk.
	CommitDelay int `json:"commit_delay,omitempty" yaml:"commit_delay,omitempty" mapstructure:"commit_delay,omitempty"`

	// Sets the minimum number of concurrent open transactions required before
	// performing "commit_delay".
	CommitSiblings int `json:"commit_siblings,omitempty" yaml:"commit_siblings,omitempty" mapstructure:"commit_siblings,omitempty"`

	// Sets the size of the dedicated buffer pool used for the commit timestamp cache.
	// Specify 0 to have this value determined as a fraction of shared_buffers.
	CommitTimestampBuffers *types.Size `json:"commit_timestamp_buffers,omitempty" yaml:"commit_timestamp_buffers,omitempty" mapstructure:"commit_timestamp_buffers,omitempty"`

	// Enables in-core computation of query identifiers.
	ComputeQueryId PostgresConfComputeQueryId `json:"compute_query_id,omitempty" yaml:"compute_query_id,omitempty" mapstructure:"compute_query_id,omitempty"`

	// Enables the planner to use constraints to optimize queries. Table scans will be
	// skipped if their constraints guarantee that no rows match the query.
	ConstraintExclusion PostgresConfConstraintExclusion `json:"constraint_exclusion,omitempty" yaml:"constraint_exclusion,omitempty" mapstructure:"constraint_exclusion,omitempty"`

	// Sets the planner's estimate of the cost of processing each index entry during
	// an index scan.
	CpuIndexTupleCost float64 `json:"cpu_index_tuple_cost,omitempty" yaml:"cpu_index_tuple_cost,omitempty" mapstructure:"cpu_index_tuple_cost,omitempty"`

	// Sets the planner's estimate of the cost of processing each operator or function
	// call.
	CpuOperatorCost float64 `json:"cpu_operator_cost,omitempty" yaml:"cpu_operator_cost,omitempty" mapstructure:"cpu_operator_cost,omitempty"`

	// Sets the planner's estimate of the cost of processing each tuple (row).
	CpuTupleCost float64 `json:"cpu_tuple_cost,omitempty" yaml:"cpu_tuple_cost,omitempty" mapstructure:"cpu_tuple_cost,omitempty"`

	// Sets whether a CREATEROLE user automatically grants the role to themselves, and
	// with which options.
	CreateroleSelfGrant *string `json:"createrole_self_grant,omitempty" yaml:"createrole_self_grant,omitempty" mapstructure:"createrole_self_grant,omitempty"`

	// Sets the planner's estimate of the fraction of a cursor's rows that will be
	// retrieved.
	CursorTupleFraction float64 `json:"cursor_tuple_fraction,omitempty" yaml:"cursor_tuple_fraction,omitempty" mapstructure:"cursor_tuple_fraction,omitempty"`

	// Sets the server's data directory.
	DataDirectory *string `json:"data_directory,omitempty" yaml:"data_directory,omitempty" mapstructure:"data_directory,omitempty"`

	// Whether to continue running after a failure to sync data files.
	DataSyncRetry bool `json:"data_sync_retry,omitempty" yaml:"data_sync_retry,omitempty" mapstructure:"data_sync_retry,omitempty"`

	// Sets the time to wait on a lock before checking for deadlock.
	DeadlockTimeout *types.Duration `json:"deadlock_timeout,omitempty" yaml:"deadlock_timeout,omitempty" mapstructure:"deadlock_timeout,omitempty"`

	// Indents parse and plan tree displays.
	DebugPrettyPrint bool `json:"debug_pretty_print,omitempty" yaml:"debug_pretty_print,omitempty" mapstructure:"debug_pretty_print,omitempty"`

	// Logs each query's parse tree.
	DebugPrintParse bool `json:"debug_print_parse,omitempty" yaml:"debug_print_parse,omitempty" mapstructure:"debug_print_parse,omitempty"`

	// Logs each query's execution plan.
	DebugPrintPlan bool `json:"debug_print_plan,omitempty" yaml:"debug_print_plan,omitempty" mapstructure:"debug_print_plan,omitempty"`

	// Logs each query's rewritten parse tree.
	DebugPrintRewritten bool `json:"debug_print_rewritten,omitempty" yaml:"debug_print_rewritten,omitempty" mapstructure:"debug_print_rewritten,omitempty"`

	// Sets the default statistics target. This applies to table columns that have not
	// had a column-specific target set via ALTER TABLE SET STATISTICS.
	DefaultStatisticsTarget int `json:"default_statistics_target,omitempty" yaml:"default_statistics_target,omitempty" mapstructure:"default_statistics_target,omitempty"`

	// Sets the default table access method for new tables.
	DefaultTableAccessMethod string `json:"default_table_access_method,omitempty" yaml:"default_table_access_method,omitempty" mapstructure:"default_table_access_method,omitempty"`

	// Sets the default tablespace to create tables and indexes in. An empty string
	// selects the database's default tablespace.
	DefaultTablespace *string `json:"default_tablespace,omitempty" yaml:"default_tablespace,omitempty" mapstructure:"default_tablespace,omitempty"`

	// Sets default text search configuration.
	DefaultTextSearchConfig string `json:"default_text_search_config,omitempty" yaml:"default_text_search_config,omitempty" mapstructure:"default_text_search_config,omitempty"`

	// Sets the default compression method for compressible values.
	DefaultToastCompression string `json:"default_toast_compression,omitempty" yaml:"default_toast_compression,omitempty" mapstructure:"default_toast_compression,omitempty"`

	// Sets the default deferrable status of new transactions.
	DefaultTransactionDeferrable bool `json:"default_transaction_deferrable,omitempty" yaml:"default_transaction_deferrable,omitempty" mapstructure:"default_transaction_deferrable,omitempty"`

	// Sets the transaction isolation level of each new transaction.
	DefaultTransactionIsolation PostgresConfDefaultTransactionIsolation `json:"default_transaction_isolation,omitempty" yaml:"default_transaction_isolation,omitempty" mapstructure:"default_transaction_isolation,omitempty"`

	// Sets the default read-only status of new transactions.
	DefaultTransactionReadOnly bool `json:"default_transaction_read_only,omitempty" yaml:"default_transaction_read_only,omitempty" mapstructure:"default_transaction_read_only,omitempty"`

	// Sets the path for dynamically loadable modules. If a dynamically loadable
	// module needs to be opened and the specified name does not have a directory
	// component (i.e., the name does not contain a slash), the system will search
	// this path for the specified file.
	DynamicLibraryPath string `json:"dynamic_library_path,omitempty" yaml:"dynamic_library_path,omitempty" mapstructure:"dynamic_library_path,omitempty"`

	// Selects the dynamic shared memory implementation used.
	DynamicSharedMemoryType *types.Size `json:"dynamic_shared_memory_type,omitempty" yaml:"dynamic_shared_memory_type,omitempty" mapstructure:"dynamic_shared_memory_type,omitempty"`

	// Sets the planner's assumption about the total size of the data caches. That is,
	// the total size of the caches (kernel cache and shared buffers) used for
	// PostgreSQL data files. This is measured in disk pages, which are normally 8 kB
	// each.
	EffectiveCacheSize *types.Size `json:"effective_cache_size,omitempty" yaml:"effective_cache_size,omitempty" mapstructure:"effective_cache_size,omitempty"`

	// Number of simultaneous requests that can be handled efficiently by the disk
	// subsystem.
	EffectiveIoConcurrency int `json:"effective_io_concurrency,omitempty" yaml:"effective_io_concurrency,omitempty" mapstructure:"effective_io_concurrency,omitempty"`

	// Enables the planner's use of async append plans.
	EnableAsyncAppend bool `json:"enable_async_append,omitempty" yaml:"enable_async_append,omitempty" mapstructure:"enable_async_append,omitempty"`

	// Enables the planner's use of bitmap-scan plans.
	EnableBitmapscan bool `json:"enable_bitmapscan,omitempty" yaml:"enable_bitmapscan,omitempty" mapstructure:"enable_bitmapscan,omitempty"`

	// Enables the planner's use of gather merge plans.
	EnableGathermerge bool `json:"enable_gathermerge,omitempty" yaml:"enable_gathermerge,omitempty" mapstructure:"enable_gathermerge,omitempty"`

	// Enables reordering of GROUP BY keys.
	EnableGroupByReordering bool `json:"enable_group_by_reordering,omitempty" yaml:"enable_group_by_reordering,omitempty" mapstructure:"enable_group_by_reordering,omitempty"`

	// Enables the planner's use of hashed aggregation plans.
	EnableHashagg bool `json:"enable_hashagg,omitempty" yaml:"enable_hashagg,omitempty" mapstructure:"enable_hashagg,omitempty"`

	// Enables the planner's use of hash join plans.
	EnableHashjoin bool `json:"enable_hashjoin,omitempty" yaml:"enable_hashjoin,omitempty" mapstructure:"enable_hashjoin,omitempty"`

	// Enables the planner's use of incremental sort steps.
	EnableIncrementalSort bool `json:"enable_incremental_sort,omitempty" yaml:"enable_incremental_sort,omitempty" mapstructure:"enable_incremental_sort,omitempty"`

	// Enables the planner's use of index-only-scan plans.
	EnableIndexonlyscan bool `json:"enable_indexonlyscan,omitempty" yaml:"enable_indexonlyscan,omitempty" mapstructure:"enable_indexonlyscan,omitempty"`

	// Enables the planner's use of index-scan plans.
	EnableIndexscan bool `json:"enable_indexscan,omitempty" yaml:"enable_indexscan,omitempty" mapstructure:"enable_indexscan,omitempty"`

	// Enables the planner's use of materialization.
	EnableMaterial bool `json:"enable_material,omitempty" yaml:"enable_material,omitempty" mapstructure:"enable_material,omitempty"`

	// Enables the planner's use of memoization.
	EnableMemoize bool `json:"enable_memoize,omitempty" yaml:"enable_memoize,omitempty" mapstructure:"enable_memoize,omitempty"`

	// Enables the planner's use of merge join plans.
	EnableMergejoin bool `json:"enable_mergejoin,omitempty" yaml:"enable_mergejoin,omitempty" mapstructure:"enable_mergejoin,omitempty"`

	// Enables the planner's use of nested-loop join plans.
	EnableNestloop bool `json:"enable_nestloop,omitempty" yaml:"enable_nestloop,omitempty" mapstructure:"enable_nestloop,omitempty"`

	// Enables the planner's use of parallel append plans.
	EnableParallelAppend bool `json:"enable_parallel_append,omitempty" yaml:"enable_parallel_append,omitempty" mapstructure:"enable_parallel_append,omitempty"`

	// Enables the planner's use of parallel hash plans.
	EnableParallelHash bool `json:"enable_parallel_hash,omitempty" yaml:"enable_parallel_hash,omitempty" mapstructure:"enable_parallel_hash,omitempty"`

	// Enables plan-time and execution-time partition pruning. Allows the query
	// planner and executor to compare partition bounds to conditions in the query to
	// determine which partitions must be scanned.
	EnablePartitionPruning bool `json:"enable_partition_pruning,omitempty" yaml:"enable_partition_pruning,omitempty" mapstructure:"enable_partition_pruning,omitempty"`

	// Enables partitionwise aggregation and grouping.
	EnablePartitionwiseAggregate bool `json:"enable_partitionwise_aggregate,omitempty" yaml:"enable_partitionwise_aggregate,omitempty" mapstructure:"enable_partitionwise_aggregate,omitempty"`

	// Enables partitionwise join.
	EnablePartitionwiseJoin bool `json:"enable_partitionwise_join,omitempty" yaml:"enable_partitionwise_join,omitempty" mapstructure:"enable_partitionwise_join,omitempty"`

	// Enables the planner's ability to produce plans that provide presorted input for
	// ORDER BY / DISTINCT aggregate functions. Allows the query planner to build
	// plans that provide presorted input for aggregate functions with an ORDER BY /
	// DISTINCT clause.  When disabled, implicit sorts are always performed during
	// execution.
	EnablePresortedAggregate bool `json:"enable_presorted_aggregate,omitempty" yaml:"enable_presorted_aggregate,omitempty" mapstructure:"enable_presorted_aggregate,omitempty"`

	// Enables the planner's use of sequential-scan plans.
	EnableSeqscan bool `json:"enable_seqscan,omitempty" yaml:"enable_seqscan,omitempty" mapstructure:"enable_seqscan,omitempty"`

	// Enables the planner's use of explicit sort steps.
	EnableSort bool `json:"enable_sort,omitempty" yaml:"enable_sort,omitempty" mapstructure:"enable_sort,omitempty"`

	// Enables the planner's use of TID scan plans.
	EnableTidscan bool `json:"enable_tidscan,omitempty" yaml:"enable_tidscan,omitempty" mapstructure:"enable_tidscan,omitempty"`

	// Warn about backslash escapes in ordinary string literals.
	EscapeStringWarning bool `json:"escape_string_warning,omitempty" yaml:"escape_string_warning,omitempty" mapstructure:"escape_string_warning,omitempty"`

	// Sets the application name used to identify PostgreSQL messages in the event
	// log.
	EventSource string `json:"event_source,omitempty" yaml:"event_source,omitempty" mapstructure:"event_source,omitempty"`

	// Enables event triggers. When enabled, event triggers will fire for all
	// applicable statements.
	EventTriggers bool `json:"event_triggers,omitempty" yaml:"event_triggers,omitempty" mapstructure:"event_triggers,omitempty"`

	// Terminate session on any error.
	ExitOnError bool `json:"exit_on_error,omitempty" yaml:"exit_on_error,omitempty" mapstructure:"exit_on_error,omitempty"`

	// Writes the postmaster PID to the specified file.
	ExternalPidFile *string `json:"external_pid_file,omitempty" yaml:"external_pid_file,omitempty" mapstructure:"external_pid_file,omitempty"`

	// Sets the number of digits displayed for floating-point values. This affects
	// real, double precision, and geometric data types. A zero or negative parameter
	// value is added to the standard number of digits (FLT_DIG or DBL_DIG as
	// appropriate). Any value greater than zero selects precise output mode.
	ExtraFloatDigits int `json:"extra_float_digits,omitempty" yaml:"extra_float_digits,omitempty" mapstructure:"extra_float_digits,omitempty"`

	// Sets the FROM-list size beyond which subqueries are not collapsed. The planner
	// will merge subqueries into upper queries if the resulting FROM list would have
	// no more than this many items.
	FromCollapseLimit int `json:"from_collapse_limit,omitempty" yaml:"from_collapse_limit,omitempty" mapstructure:"from_collapse_limit,omitempty"`

	// Forces synchronization of updates to disk. The server will use the fsync()
	// system call in several places to make sure that updates are physically written
	// to disk. This ensures that a database cluster will recover to a consistent
	// state after an operating system or hardware crash.
	Fsync bool `json:"fsync,omitempty" yaml:"fsync,omitempty" mapstructure:"fsync,omitempty"`

	// Writes full pages to WAL when first modified after a checkpoint. A page write
	// in process during an operating system crash might be only partially written to
	// disk.  During recovery, the row changes stored in WAL are not enough to
	// recover.  This option writes pages when first modified after a checkpoint to
	// WAL so full recovery is possible.
	FullPageWrites bool `json:"full_page_writes,omitempty" yaml:"full_page_writes,omitempty" mapstructure:"full_page_writes,omitempty"`

	// Enables genetic query optimization. This algorithm attempts to do planning
	// without exhaustive searching.
	Geqo bool `json:"geqo,omitempty" yaml:"geqo,omitempty" mapstructure:"geqo,omitempty"`

	// GEQO: effort is used to set the default for other GEQO parameters.
	GeqoEffort int `json:"geqo_effort,omitempty" yaml:"geqo_effort,omitempty" mapstructure:"geqo_effort,omitempty"`

	// GEQO: number of iterations of the algorithm. Zero selects a suitable default
	// value.
	GeqoGenerations int `json:"geqo_generations,omitempty" yaml:"geqo_generations,omitempty" mapstructure:"geqo_generations,omitempty"`

	// GEQO: number of individuals in the population. Zero selects a suitable default
	// value.
	GeqoPoolSize int `json:"geqo_pool_size,omitempty" yaml:"geqo_pool_size,omitempty" mapstructure:"geqo_pool_size,omitempty"`

	// GEQO: seed for random path selection.
	GeqoSeed float64 `json:"geqo_seed,omitempty" yaml:"geqo_seed,omitempty" mapstructure:"geqo_seed,omitempty"`

	// GEQO: selective pressure within the population.
	GeqoSelectionBias float64 `json:"geqo_selection_bias,omitempty" yaml:"geqo_selection_bias,omitempty" mapstructure:"geqo_selection_bias,omitempty"`

	// Sets the threshold of FROM items beyond which GEQO is used.
	GeqoThreshold int `json:"geqo_threshold,omitempty" yaml:"geqo_threshold,omitempty" mapstructure:"geqo_threshold,omitempty"`

	// Sets the maximum allowed result for exact search by GIN.
	GinFuzzySearchLimit int `json:"gin_fuzzy_search_limit,omitempty" yaml:"gin_fuzzy_search_limit,omitempty" mapstructure:"gin_fuzzy_search_limit,omitempty"`

	// Sets the maximum size of the pending list for GIN index.
	GinPendingListLimit *types.Size `json:"gin_pending_list_limit,omitempty" yaml:"gin_pending_list_limit,omitempty" mapstructure:"gin_pending_list_limit,omitempty"`

	// Sets whether GSSAPI delegation should be accepted from the client.
	GssAcceptDelegation bool `json:"gss_accept_delegation,omitempty" yaml:"gss_accept_delegation,omitempty" mapstructure:"gss_accept_delegation,omitempty"`

	// Multiple of "work_mem" to use for hash tables.
	HashMemMultiplier float64 `json:"hash_mem_multiplier,omitempty" yaml:"hash_mem_multiplier,omitempty" mapstructure:"hash_mem_multiplier,omitempty"`

	// Sets the server's "hba" configuration file.
	HbaFile *string `json:"hba_file,omitempty" yaml:"hba_file,omitempty" mapstructure:"hba_file,omitempty"`

	// Allows connections and queries during recovery.
	HotStandby bool `json:"hot_standby,omitempty" yaml:"hot_standby,omitempty" mapstructure:"hot_standby,omitempty"`

	// Allows feedback from a hot standby to the primary that will avoid query
	// conflicts.
	HotStandbyFeedback bool `json:"hot_standby_feedback,omitempty" yaml:"hot_standby_feedback,omitempty" mapstructure:"hot_standby_feedback,omitempty"`

	// The size of huge page that should be requested.
	HugePageSize *types.Size `json:"huge_page_size,omitempty" yaml:"huge_page_size,omitempty" mapstructure:"huge_page_size,omitempty"`

	// Use of huge pages on Linux or Windows.
	HugePages string `json:"huge_pages,omitempty" yaml:"huge_pages,omitempty" mapstructure:"huge_pages,omitempty"`

	// Log level for reporting invalid ICU locale strings.
	IcuValidationLevel string `json:"icu_validation_level,omitempty" yaml:"icu_validation_level,omitempty" mapstructure:"icu_validation_level,omitempty"`

	// Sets the server's "ident" configuration file.
	IdentFile *string `json:"ident_file,omitempty" yaml:"ident_file,omitempty" mapstructure:"ident_file,omitempty"`

	// Sets the maximum allowed idle time between queries, when in a transaction. A
	// value of 0 turns off the timeout.
	IdleInTransactionSessionTimeout *types.Duration `json:"idle_in_transaction_session_timeout,omitempty" yaml:"idle_in_transaction_session_timeout,omitempty" mapstructure:"idle_in_transaction_session_timeout,omitempty"`

	// Sets the maximum allowed idle time between queries, when not in a transaction.
	// A value of 0 turns off the timeout.
	IdleSessionTimeout *types.Duration `json:"idle_session_timeout,omitempty" yaml:"idle_session_timeout,omitempty" mapstructure:"idle_session_timeout,omitempty"`

	// Limit on the size of data reads and writes.
	IoCombineLimit *types.Size `json:"io_combine_limit,omitempty" yaml:"io_combine_limit,omitempty" mapstructure:"io_combine_limit,omitempty"`

	// Allow JIT compilation.
	Jit bool `json:"jit,omitempty" yaml:"jit,omitempty" mapstructure:"jit,omitempty"`

	// Perform JIT compilation if query is more expensive. -1 disables JIT
	// compilation.
	JitAboveCost float64 `json:"jit_above_cost,omitempty" yaml:"jit_above_cost,omitempty" mapstructure:"jit_above_cost,omitempty"`

	// Perform JIT inlining if query is more expensive. -1 disables inlining.
	JitInlineAboveCost float64 `json:"jit_inline_above_cost,omitempty" yaml:"jit_inline_above_cost,omitempty" mapstructure:"jit_inline_above_cost,omitempty"`

	// Optimize JIT-compiled functions if query is more expensive. -1 disables
	// optimization.
	JitOptimizeAboveCost float64 `json:"jit_optimize_above_cost,omitempty" yaml:"jit_optimize_above_cost,omitempty" mapstructure:"jit_optimize_above_cost,omitempty"`

	// JIT provider to use.
	JitProvider string `json:"jit_provider,omitempty" yaml:"jit_provider,omitempty" mapstructure:"jit_provider,omitempty"`

	// Sets the FROM-list size beyond which JOIN constructs are not flattened. The
	// planner will flatten explicit JOIN constructs into lists of FROM items whenever
	// a list of no more than this many items would result.
	JoinCollapseLimit int `json:"join_collapse_limit,omitempty" yaml:"join_collapse_limit,omitempty" mapstructure:"join_collapse_limit,omitempty"`

	// Sets whether Kerberos and GSSAPI user names should be treated as
	// case-insensitive.
	KrbCaseinsUsers bool `json:"krb_caseins_users,omitempty" yaml:"krb_caseins_users,omitempty" mapstructure:"krb_caseins_users,omitempty"`

	// Sets the location of the Kerberos server key file.
	KrbServerKeyfile string `json:"krb_server_keyfile,omitempty" yaml:"krb_server_keyfile,omitempty" mapstructure:"krb_server_keyfile,omitempty"`

	// Sets the language in which messages are displayed.
	LcMessages *string `json:"lc_messages,omitempty" yaml:"lc_messages,omitempty" mapstructure:"lc_messages,omitempty"`

	// Sets the locale for formatting monetary amounts.
	LcMonetary string `json:"lc_monetary,omitempty" yaml:"lc_monetary,omitempty" mapstructure:"lc_monetary,omitempty"`

	// Sets the locale for formatting numbers.
	LcNumeric string `json:"lc_numeric,omitempty" yaml:"lc_numeric,omitempty" mapstructure:"lc_numeric,omitempty"`

	// Sets the locale for formatting date and time values.
	LcTime string `json:"lc_time,omitempty" yaml:"lc_time,omitempty" mapstructure:"lc_time,omitempty"`

	// Sets the host name or IP address(es) to listen to.
	ListenAddresses string `json:"listen_addresses,omitempty" yaml:"listen_addresses,omitempty" mapstructure:"listen_addresses,omitempty"`

	// Enables backward compatibility mode for privilege checks on large objects.
	// Skips privilege checks when reading or modifying large objects, for
	// compatibility with PostgreSQL releases prior to 9.0.
	LoCompatPrivileges bool `json:"lo_compat_privileges,omitempty" yaml:"lo_compat_privileges,omitempty" mapstructure:"lo_compat_privileges,omitempty"`

	// Lists unprivileged shared libraries to preload into each backend.
	LocalPreloadLibraries *string `json:"local_preload_libraries,omitempty" yaml:"local_preload_libraries,omitempty" mapstructure:"local_preload_libraries,omitempty"`

	// Sets the maximum allowed duration of any wait for a lock. A value of 0 turns
	// off the timeout.
	LockTimeout *types.Duration `json:"lock_timeout,omitempty" yaml:"lock_timeout,omitempty" mapstructure:"lock_timeout,omitempty"`

	// Sets the minimum execution time above which autovacuum actions will be logged.
	// Zero prints all actions. -1 turns autovacuum logging off.
	LogAutovacuumMinDuration int `json:"log_autovacuum_min_duration,omitempty" yaml:"log_autovacuum_min_duration,omitempty" mapstructure:"log_autovacuum_min_duration,omitempty"`

	// Logs each checkpoint.
	LogCheckpoints bool `json:"log_checkpoints,omitempty" yaml:"log_checkpoints,omitempty" mapstructure:"log_checkpoints,omitempty"`

	// Logs each successful connection.
	LogConnections bool `json:"log_connections,omitempty" yaml:"log_connections,omitempty" mapstructure:"log_connections,omitempty"`

	// Sets the destination for server log output. Valid values are combinations of
	// "stderr", "syslog", "csvlog", "jsonlog", and "eventlog", depending on the
	// platform.
	LogDestination string `json:"log_destination,omitempty" yaml:"log_destination,omitempty" mapstructure:"log_destination,omitempty"`

	// Sets the destination directory for log files. Can be specified as relative to
	// the data directory or as absolute path.
	LogDirectory string `json:"log_directory,omitempty" yaml:"log_directory,omitempty" mapstructure:"log_directory,omitempty"`

	// Logs end of a session, including duration.
	LogDisconnections bool `json:"log_disconnections,omitempty" yaml:"log_disconnections,omitempty" mapstructure:"log_disconnections,omitempty"`

	// Logs the duration of each completed SQL statement.
	LogDuration bool `json:"log_duration,omitempty" yaml:"log_duration,omitempty" mapstructure:"log_duration,omitempty"`

	// Sets the verbosity of logged messages.
	LogErrorVerbosity string `json:"log_error_verbosity,omitempty" yaml:"log_error_verbosity,omitempty" mapstructure:"log_error_verbosity,omitempty"`

	// Writes executor performance statistics to the server log.
	LogExecutorStats bool `json:"log_executor_stats,omitempty" yaml:"log_executor_stats,omitempty" mapstructure:"log_executor_stats,omitempty"`

	// Sets the file permissions for log files. The parameter value is expected to be
	// a numeric mode specification in the form accepted by the chmod and umask system
	// calls. (To use the customary octal format the number must start with a 0
	// (zero).)
	LogFileMode int `json:"log_file_mode,omitempty" yaml:"log_file_mode,omitempty" mapstructure:"log_file_mode,omitempty"`

	// Sets the file name pattern for log files.
	LogFilename string `json:"log_filename,omitempty" yaml:"log_filename,omitempty" mapstructure:"log_filename,omitempty"`

	// Logs the host name in the connection logs. By default, connection logs only
	// show the IP address of the connecting host. If you want them to show the host
	// name you can turn this on, but depending on your host name resolution setup it
	// might impose a non-negligible performance penalty.
	LogHostname bool `json:"log_hostname,omitempty" yaml:"log_hostname,omitempty" mapstructure:"log_hostname,omitempty"`

	// Controls information prefixed to each log line. If blank, no prefix is used.
	LogLinePrefix string `json:"log_line_prefix,omitempty" yaml:"log_line_prefix,omitempty" mapstructure:"log_line_prefix,omitempty"`

	// Logs long lock waits.
	LogLockWaits bool `json:"log_lock_waits,omitempty" yaml:"log_lock_waits,omitempty" mapstructure:"log_lock_waits,omitempty"`

	// Sets the minimum execution time above which a sample of statements will be
	// logged. Sampling is determined by log_statement_sample_rate. Zero logs a sample
	// of all queries. -1 turns this feature off.
	LogMinDurationSample int `json:"log_min_duration_sample,omitempty" yaml:"log_min_duration_sample,omitempty" mapstructure:"log_min_duration_sample,omitempty"`

	// Sets the minimum execution time above which all statements will be logged. Zero
	// prints all queries. -1 turns this feature off.
	LogMinDurationStatement int `json:"log_min_duration_statement,omitempty" yaml:"log_min_duration_statement,omitempty" mapstructure:"log_min_duration_statement,omitempty"`

	// Causes all statements generating error at or above this level to be logged.
	// Each level includes all the levels that follow it. The later the level, the
	// fewer messages are sent.
	LogMinErrorStatement string `json:"log_min_error_statement,omitempty" yaml:"log_min_error_statement,omitempty" mapstructure:"log_min_error_statement,omitempty"`

	// Sets the message levels that are logged. Each level includes all the levels
	// that follow it. The later the level, the fewer messages are sent.
	LogMinMessages PostgresConfLogMinMessages `json:"log_min_messages,omitempty" yaml:"log_min_messages,omitempty" mapstructure:"log_min_messages,omitempty"`

	// Sets the maximum length in bytes of data logged for bind parameter values when
	// logging statements. -1 to print values in full.
	LogParameterMaxLength int `json:"log_parameter_max_length,omitempty" yaml:"log_parameter_max_length,omitempty" mapstructure:"log_parameter_max_length,omitempty"`

	// Sets the maximum length in bytes of data logged for bind parameter values when
	// logging statements, on error. -1 to print values in full.
	LogParameterMaxLengthOnError int `json:"log_parameter_max_length_on_error,omitempty" yaml:"log_parameter_max_length_on_error,omitempty" mapstructure:"log_parameter_max_length_on_error,omitempty"`

	// Writes parser performance statistics to the server log.
	LogParserStats bool `json:"log_parser_stats,omitempty" yaml:"log_parser_stats,omitempty" mapstructure:"log_parser_stats,omitempty"`

	// Writes planner performance statistics to the server log.
	LogPlannerStats bool `json:"log_planner_stats,omitempty" yaml:"log_planner_stats,omitempty" mapstructure:"log_planner_stats,omitempty"`

	// Logs standby recovery conflict waits.
	LogRecoveryConflictWaits bool `json:"log_recovery_conflict_waits,omitempty" yaml:"log_recovery_conflict_waits,omitempty" mapstructure:"log_recovery_conflict_waits,omitempty"`

	// Logs each replication command.
	LogReplicationCommands bool `json:"log_replication_commands,omitempty" yaml:"log_replication_commands,omitempty" mapstructure:"log_replication_commands,omitempty"`

	// Sets the amount of time to wait before forcing log file rotation.
	LogRotationAge int `json:"log_rotation_age,omitempty" yaml:"log_rotation_age,omitempty" mapstructure:"log_rotation_age,omitempty"`

	// Sets the maximum size a log file can reach before being rotated.
	LogRotationSize int `json:"log_rotation_size,omitempty" yaml:"log_rotation_size,omitempty" mapstructure:"log_rotation_size,omitempty"`

	// Time between progress updates for long-running startup operations. 0 turns this
	// feature off.
	LogStartupProgressInterval int `json:"log_startup_progress_interval,omitempty" yaml:"log_startup_progress_interval,omitempty" mapstructure:"log_startup_progress_interval,omitempty"`

	// Sets the type of statements logged.
	LogStatement PostgresConfLogStatement `json:"log_statement,omitempty" yaml:"log_statement,omitempty" mapstructure:"log_statement,omitempty"`

	// Fraction of statements exceeding "log_min_duration_sample" to be logged. Use a
	// value between 0.0 (never log) and 1.0 (always log).
	LogStatementSampleRate float64 `json:"log_statement_sample_rate,omitempty" yaml:"log_statement_sample_rate,omitempty" mapstructure:"log_statement_sample_rate,omitempty"`

	// Writes cumulative performance statistics to the server log.
	LogStatementStats bool `json:"log_statement_stats,omitempty" yaml:"log_statement_stats,omitempty" mapstructure:"log_statement_stats,omitempty"`

	// Log the use of temporary files larger than this number of kilobytes. Zero logs
	// all files. The default is -1 (turning this feature off).
	LogTempFiles *types.Size `json:"log_temp_files,omitempty" yaml:"log_temp_files,omitempty" mapstructure:"log_temp_files,omitempty"`

	// Sets the time zone to use in log messages.
	LogTimezone string `json:"log_timezone,omitempty" yaml:"log_timezone,omitempty" mapstructure:"log_timezone,omitempty"`

	// Sets the fraction of transactions from which to log all statements. Use a value
	// between 0.0 (never log) and 1.0 (log all statements for all transactions).
	LogTransactionSampleRate float64 `json:"log_transaction_sample_rate,omitempty" yaml:"log_transaction_sample_rate,omitempty" mapstructure:"log_transaction_sample_rate,omitempty"`

	// Truncate existing log files of same name during log rotation.
	LogTruncateOnRotation bool `json:"log_truncate_on_rotation,omitempty" yaml:"log_truncate_on_rotation,omitempty" mapstructure:"log_truncate_on_rotation,omitempty"`

	// Start a subprocess to capture stderr, csvlog and/or jsonlog into log files.
	LoggingCollector bool `json:"logging_collector,omitempty" yaml:"logging_collector,omitempty" mapstructure:"logging_collector,omitempty"`

	// Sets the maximum memory to be used for logical decoding. This much memory can
	// be used by each internal reorder buffer before spilling to disk.
	LogicalDecodingWorkMem *types.Size `json:"logical_decoding_work_mem,omitempty" yaml:"logical_decoding_work_mem,omitempty" mapstructure:"logical_decoding_work_mem,omitempty"`

	// A variant of "effective_io_concurrency" that is used for maintenance work.
	MaintenanceIoConcurrency int `json:"maintenance_io_concurrency,omitempty" yaml:"maintenance_io_concurrency,omitempty" mapstructure:"maintenance_io_concurrency,omitempty"`

	// Sets the maximum memory to be used for maintenance operations. This includes
	// operations such as VACUUM and CREATE INDEX.
	MaintenanceWorkMem *types.Size `json:"maintenance_work_mem,omitempty" yaml:"maintenance_work_mem,omitempty" mapstructure:"maintenance_work_mem,omitempty"`

	// Sets the maximum number of concurrent connections.
	MaxConnections int `json:"max_connections,omitempty" yaml:"max_connections,omitempty" mapstructure:"max_connections,omitempty"`

	// Sets the maximum number of simultaneously open files for each server process.
	MaxFilesPerProcess int `json:"max_files_per_process,omitempty" yaml:"max_files_per_process,omitempty" mapstructure:"max_files_per_process,omitempty"`

	// Sets the maximum number of locks per transaction. The shared lock table is
	// sized on the assumption that at most "max_locks_per_transaction" objects per
	// server process or prepared transaction will need to be locked at any one time.
	MaxLocksPerTransaction int `json:"max_locks_per_transaction,omitempty" yaml:"max_locks_per_transaction,omitempty" mapstructure:"max_locks_per_transaction,omitempty"`

	// Maximum number of logical replication worker processes.
	MaxLogicalReplicationWorkers int `json:"max_logical_replication_workers,omitempty" yaml:"max_logical_replication_workers,omitempty" mapstructure:"max_logical_replication_workers,omitempty"`

	// Sets the maximum number of allocated pages for NOTIFY / LISTEN queue.
	MaxNotifyQueuePages int `json:"max_notify_queue_pages,omitempty" yaml:"max_notify_queue_pages,omitempty" mapstructure:"max_notify_queue_pages,omitempty"`

	// Maximum number of parallel apply workers per subscription.
	MaxParallelApplyWorkersPerSubscription int `json:"max_parallel_apply_workers_per_subscription,omitempty" yaml:"max_parallel_apply_workers_per_subscription,omitempty" mapstructure:"max_parallel_apply_workers_per_subscription,omitempty"`

	// Sets the maximum number of parallel processes per maintenance operation.
	MaxParallelMaintenanceWorkers int `json:"max_parallel_maintenance_workers,omitempty" yaml:"max_parallel_maintenance_workers,omitempty" mapstructure:"max_parallel_maintenance_workers,omitempty"`

	// Sets the maximum number of parallel workers that can be active at one time.
	MaxParallelWorkers int `json:"max_parallel_workers,omitempty" yaml:"max_parallel_workers,omitempty" mapstructure:"max_parallel_workers,omitempty"`

	// Sets the maximum number of parallel processes per executor node.
	MaxParallelWorkersPerGather int `json:"max_parallel_workers_per_gather,omitempty" yaml:"max_parallel_workers_per_gather,omitempty" mapstructure:"max_parallel_workers_per_gather,omitempty"`

	// Sets the maximum number of predicate-locked tuples per page. If more than this
	// number of tuples on the same page are locked by a connection, those locks are
	// replaced by a page-level lock.
	MaxPredLocksPerPage int `json:"max_pred_locks_per_page,omitempty" yaml:"max_pred_locks_per_page,omitempty" mapstructure:"max_pred_locks_per_page,omitempty"`

	// Sets the maximum number of predicate-locked pages and tuples per relation. If
	// more than this total of pages and tuples in the same relation are locked by a
	// connection, those locks are replaced by a relation-level lock.
	MaxPredLocksPerRelation int `json:"max_pred_locks_per_relation,omitempty" yaml:"max_pred_locks_per_relation,omitempty" mapstructure:"max_pred_locks_per_relation,omitempty"`

	// Sets the maximum number of predicate locks per transaction. The shared
	// predicate lock table is sized on the assumption that at most
	// "max_pred_locks_per_transaction" objects per server process or prepared
	// transaction will need to be locked at any one time.
	MaxPredLocksPerTransaction int `json:"max_pred_locks_per_transaction,omitempty" yaml:"max_pred_locks_per_transaction,omitempty" mapstructure:"max_pred_locks_per_transaction,omitempty"`

	// Sets the maximum number of simultaneously prepared transactions.
	MaxPreparedTransactions *types.Size `json:"max_prepared_transactions,omitempty" yaml:"max_prepared_transactions,omitempty" mapstructure:"max_prepared_transactions,omitempty"`

	// Sets the maximum number of simultaneously defined replication slots.
	MaxReplicationSlots int `json:"max_replication_slots,omitempty" yaml:"max_replication_slots,omitempty" mapstructure:"max_replication_slots,omitempty"`

	// Sets the maximum WAL size that can be reserved by replication slots.
	// Replication slots will be marked as failed, and segments released for deletion
	// or recycling, if this much space is occupied by WAL on disk.
	MaxSlotWalKeepSize int `json:"max_slot_wal_keep_size,omitempty" yaml:"max_slot_wal_keep_size,omitempty" mapstructure:"max_slot_wal_keep_size,omitempty"`

	// Sets the maximum stack depth, in kilobytes.
	MaxStackDepth *types.Size `json:"max_stack_depth,omitempty" yaml:"max_stack_depth,omitempty" mapstructure:"max_stack_depth,omitempty"`

	// Sets the maximum delay before canceling queries when a hot standby server is
	// processing archived WAL data.
	MaxStandbyArchiveDelay int `json:"max_standby_archive_delay,omitempty" yaml:"max_standby_archive_delay,omitempty" mapstructure:"max_standby_archive_delay,omitempty"`

	// Sets the maximum delay before canceling queries when a hot standby server is
	// processing streamed WAL data.
	MaxStandbyStreamingDelay int `json:"max_standby_streaming_delay,omitempty" yaml:"max_standby_streaming_delay,omitempty" mapstructure:"max_standby_streaming_delay,omitempty"`

	// Maximum number of table synchronization workers per subscription.
	MaxSyncWorkersPerSubscription int `json:"max_sync_workers_per_subscription,omitempty" yaml:"max_sync_workers_per_subscription,omitempty" mapstructure:"max_sync_workers_per_subscription,omitempty"`

	// Sets the maximum number of simultaneously running WAL sender processes.
	MaxWalSenders int `json:"max_wal_senders,omitempty" yaml:"max_wal_senders,omitempty" mapstructure:"max_wal_senders,omitempty"`

	// Sets the WAL size that triggers a checkpoint.
	MaxWalSize int `json:"max_wal_size,omitempty" yaml:"max_wal_size,omitempty" mapstructure:"max_wal_size,omitempty"`

	// Maximum number of concurrent worker processes.
	MaxWorkerProcesses int `json:"max_worker_processes,omitempty" yaml:"max_worker_processes,omitempty" mapstructure:"max_worker_processes,omitempty"`

	// Amount of dynamic shared memory reserved at startup.
	MinDynamicSharedMemory *types.Size `json:"min_dynamic_shared_memory,omitempty" yaml:"min_dynamic_shared_memory,omitempty" mapstructure:"min_dynamic_shared_memory,omitempty"`

	// Sets the minimum amount of index data for a parallel scan. If the planner
	// estimates that it will read a number of index pages too small to reach this
	// limit, a parallel scan will not be considered.
	MinParallelIndexScanSize int `json:"min_parallel_index_scan_size,omitempty" yaml:"min_parallel_index_scan_size,omitempty" mapstructure:"min_parallel_index_scan_size,omitempty"`

	// Sets the minimum amount of table data for a parallel scan. If the planner
	// estimates that it will read a number of table pages too small to reach this
	// limit, a parallel scan will not be considered.
	MinParallelTableScanSize int `json:"min_parallel_table_scan_size,omitempty" yaml:"min_parallel_table_scan_size,omitempty" mapstructure:"min_parallel_table_scan_size,omitempty"`

	// Sets the minimum size to shrink the WAL to.
	MinWalSize int `json:"min_wal_size,omitempty" yaml:"min_wal_size,omitempty" mapstructure:"min_wal_size,omitempty"`

	// Sets the size of the dedicated buffer pool used for the MultiXact member cache.
	MultixactMemberBuffers *types.Size `json:"multixact_member_buffers,omitempty" yaml:"multixact_member_buffers,omitempty" mapstructure:"multixact_member_buffers,omitempty"`

	// Sets the size of the dedicated buffer pool used for the MultiXact offset cache.
	MultixactOffsetBuffers *types.Size `json:"multixact_offset_buffers,omitempty" yaml:"multixact_offset_buffers,omitempty" mapstructure:"multixact_offset_buffers,omitempty"`

	// Sets the size of the dedicated buffer pool used for the LISTEN/NOTIFY message
	// cache.
	NotifyBuffers *types.Size `json:"notify_buffers,omitempty" yaml:"notify_buffers,omitempty" mapstructure:"notify_buffers,omitempty"`

	// Controls whether Gather and Gather Merge also run subplans. Should gather nodes
	// also run subplans or just gather tuples?
	ParallelLeaderParticipation bool `json:"parallel_leader_participation,omitempty" yaml:"parallel_leader_participation,omitempty" mapstructure:"parallel_leader_participation,omitempty"`

	// Sets the planner's estimate of the cost of starting up worker processes for
	// parallel query.
	ParallelSetupCost float64 `json:"parallel_setup_cost,omitempty" yaml:"parallel_setup_cost,omitempty" mapstructure:"parallel_setup_cost,omitempty"`

	// Sets the planner's estimate of the cost of passing each tuple (row) from worker
	// to leader backend.
	ParallelTupleCost float64 `json:"parallel_tuple_cost,omitempty" yaml:"parallel_tuple_cost,omitempty" mapstructure:"parallel_tuple_cost,omitempty"`

	// Chooses the algorithm for encrypting passwords.
	PasswordEncryption PostgresConfPasswordEncryption `json:"password_encryption,omitempty" yaml:"password_encryption,omitempty" mapstructure:"password_encryption,omitempty"`

	// Controls the planner's selection of custom or generic plan. Prepared statements
	// can have custom and generic plans, and the planner will attempt to choose which
	// is better.  This can be set to override the default behavior.
	PlanCacheMode string `json:"plan_cache_mode,omitempty" yaml:"plan_cache_mode,omitempty" mapstructure:"plan_cache_mode,omitempty"`

	// Sets the TCP port the server listens on.
	Port int `json:"port,omitempty" yaml:"port,omitempty" mapstructure:"port,omitempty"`

	// Sets the connection string to be used to connect to the sending server.
	PrimaryConninfo *string `json:"primary_conninfo,omitempty" yaml:"primary_conninfo,omitempty" mapstructure:"primary_conninfo,omitempty"`

	// Sets the name of the replication slot to use on the sending server.
	PrimarySlotName *string `json:"primary_slot_name,omitempty" yaml:"primary_slot_name,omitempty" mapstructure:"primary_slot_name,omitempty"`

	// When generating SQL fragments, quote all identifiers.
	QuoteAllIdentifiers bool `json:"quote_all_identifiers,omitempty" yaml:"quote_all_identifiers,omitempty" mapstructure:"quote_all_identifiers,omitempty"`

	// Sets the planner's estimate of the cost of a nonsequentially fetched disk page.
	RandomPageCost float64 `json:"random_page_cost,omitempty" yaml:"random_page_cost,omitempty" mapstructure:"random_page_cost,omitempty"`

	// Sets the shell command that will be executed once at the end of recovery.
	RecoveryEndCommand *string `json:"recovery_end_command,omitempty" yaml:"recovery_end_command,omitempty" mapstructure:"recovery_end_command,omitempty"`

	// Sets the method for synchronizing the data directory before crash recovery.
	RecoveryInitSyncMethod string `json:"recovery_init_sync_method,omitempty" yaml:"recovery_init_sync_method,omitempty" mapstructure:"recovery_init_sync_method,omitempty"`

	// Sets the minimum delay for applying changes during recovery.
	RecoveryMinApplyDelay int `json:"recovery_min_apply_delay,omitempty" yaml:"recovery_min_apply_delay,omitempty" mapstructure:"recovery_min_apply_delay,omitempty"`

	// Prefetch referenced blocks during recovery. Look ahead in the WAL to find
	// references to uncached data.
	RecoveryPrefetch *types.Size `json:"recovery_prefetch,omitempty" yaml:"recovery_prefetch,omitempty" mapstructure:"recovery_prefetch,omitempty"`

	// Set to "immediate" to end recovery as soon as a consistent state is reached.
	RecoveryTarget *string `json:"recovery_target,omitempty" yaml:"recovery_target,omitempty" mapstructure:"recovery_target,omitempty"`

	// Sets the action to perform upon reaching the recovery target.
	RecoveryTargetAction string `json:"recovery_target_action,omitempty" yaml:"recovery_target_action,omitempty" mapstructure:"recovery_target_action,omitempty"`

	// Sets whether to include or exclude transaction with recovery target.
	RecoveryTargetInclusive bool `json:"recovery_target_inclusive,omitempty" yaml:"recovery_target_inclusive,omitempty" mapstructure:"recovery_target_inclusive,omitempty"`

	// Sets the LSN of the write-ahead log location up to which recovery will proceed.
	RecoveryTargetLsn *string `json:"recovery_target_lsn,omitempty" yaml:"recovery_target_lsn,omitempty" mapstructure:"recovery_target_lsn,omitempty"`

	// Sets the named restore point up to which recovery will proceed.
	RecoveryTargetName *string `json:"recovery_target_name,omitempty" yaml:"recovery_target_name,omitempty" mapstructure:"recovery_target_name,omitempty"`

	// Sets the time stamp up to which recovery will proceed.
	RecoveryTargetTime *string `json:"recovery_target_time,omitempty" yaml:"recovery_target_time,omitempty" mapstructure:"recovery_target_time,omitempty"`

	// Specifies the timeline to recover into.
	RecoveryTargetTimeline string `json:"recovery_target_timeline,omitempty" yaml:"recovery_target_timeline,omitempty" mapstructure:"recovery_target_timeline,omitempty"`

	// Sets the transaction ID up to which recovery will proceed.
	RecoveryTargetXid *string `json:"recovery_target_xid,omitempty" yaml:"recovery_target_xid,omitempty" mapstructure:"recovery_target_xid,omitempty"`

	// Sets the planner's estimate of the average size of a recursive query's working
	// table.
	RecursiveWorktableFactor *types.Size `json:"recursive_worktable_factor,omitempty" yaml:"recursive_worktable_factor,omitempty" mapstructure:"recursive_worktable_factor,omitempty"`

	// Sets the number of connection slots reserved for roles with privileges of
	// pg_use_reserved_connections.
	ReservedConnections int `json:"reserved_connections,omitempty" yaml:"reserved_connections,omitempty" mapstructure:"reserved_connections,omitempty"`

	// Reinitialize server after backend crash.
	RestartAfterCrash bool `json:"restart_after_crash,omitempty" yaml:"restart_after_crash,omitempty" mapstructure:"restart_after_crash,omitempty"`

	// Sets the shell command that will be called to retrieve an archived WAL file.
	RestoreCommand *string `json:"restore_command,omitempty" yaml:"restore_command,omitempty" mapstructure:"restore_command,omitempty"`

	// Enable row security. When enabled, row security will be applied to all users.
	RowSecurity bool `json:"row_security,omitempty" yaml:"row_security,omitempty" mapstructure:"row_security,omitempty"`

	// Sets the iteration count for SCRAM secret generation.
	ScramIterations int `json:"scram_iterations,omitempty" yaml:"scram_iterations,omitempty" mapstructure:"scram_iterations,omitempty"`

	// Sets the schema search order for names that are not schema-qualified.
	SearchPath string `json:"search_path,omitempty" yaml:"search_path,omitempty" mapstructure:"search_path,omitempty"`

	// Sets the planner's estimate of the cost of a sequentially fetched disk page.
	SeqPageCost float64 `json:"seq_page_cost,omitempty" yaml:"seq_page_cost,omitempty" mapstructure:"seq_page_cost,omitempty"`

	// Sets the size of the dedicated buffer pool used for the serializable
	// transaction cache.
	SerializableBuffers *types.Size `json:"serializable_buffers,omitempty" yaml:"serializable_buffers,omitempty" mapstructure:"serializable_buffers,omitempty"`

	// Lists shared libraries to preload into each backend.
	SessionPreloadLibraries *string `json:"session_preload_libraries,omitempty" yaml:"session_preload_libraries,omitempty" mapstructure:"session_preload_libraries,omitempty"`

	// Sets the session's behavior for triggers and rewrite rules.
	SessionReplicationRole string `json:"session_replication_role,omitempty" yaml:"session_replication_role,omitempty" mapstructure:"session_replication_role,omitempty"`

	// Sets the number of shared memory buffers used by the server.
	SharedBuffers *types.Size `json:"shared_buffers,omitempty" yaml:"shared_buffers,omitempty" mapstructure:"shared_buffers,omitempty"`

	// Selects the shared memory implementation used for the main shared memory
	// region.
	SharedMemoryType *types.Size `json:"shared_memory_type,omitempty" yaml:"shared_memory_type,omitempty" mapstructure:"shared_memory_type,omitempty"`

	// Lists shared libraries to preload into server.
	SharedPreloadLibraries *string `json:"shared_preload_libraries,omitempty" yaml:"shared_preload_libraries,omitempty" mapstructure:"shared_preload_libraries,omitempty"`

	// Enables SSL connections.
	Ssl bool `json:"ssl,omitempty" yaml:"ssl,omitempty" mapstructure:"ssl,omitempty"`

	// Location of the SSL certificate authority file.
	SslCaFile *string `json:"ssl_ca_file,omitempty" yaml:"ssl_ca_file,omitempty" mapstructure:"ssl_ca_file,omitempty"`

	// Location of the SSL server certificate file.
	SslCertFile string `json:"ssl_cert_file,omitempty" yaml:"ssl_cert_file,omitempty" mapstructure:"ssl_cert_file,omitempty"`

	// Sets the list of allowed SSL ciphers.
	SslCiphers string `json:"ssl_ciphers,omitempty" yaml:"ssl_ciphers,omitempty" mapstructure:"ssl_ciphers,omitempty"`

	// Location of the SSL certificate revocation list directory.
	SslCrlDir *string `json:"ssl_crl_dir,omitempty" yaml:"ssl_crl_dir,omitempty" mapstructure:"ssl_crl_dir,omitempty"`

	// Location of the SSL certificate revocation list file.
	SslCrlFile *string `json:"ssl_crl_file,omitempty" yaml:"ssl_crl_file,omitempty" mapstructure:"ssl_crl_file,omitempty"`

	// Location of the SSL DH parameters file.
	SslDhParamsFile *string `json:"ssl_dh_params_file,omitempty" yaml:"ssl_dh_params_file,omitempty" mapstructure:"ssl_dh_params_file,omitempty"`

	// Sets the curve to use for ECDH.
	SslEcdhCurve string `json:"ssl_ecdh_curve,omitempty" yaml:"ssl_ecdh_curve,omitempty" mapstructure:"ssl_ecdh_curve,omitempty"`

	// Location of the SSL server private key file.
	SslKeyFile string `json:"ssl_key_file,omitempty" yaml:"ssl_key_file,omitempty" mapstructure:"ssl_key_file,omitempty"`

	// Sets the maximum SSL/TLS protocol version to use.
	SslMaxProtocolVersion *string `json:"ssl_max_protocol_version,omitempty" yaml:"ssl_max_protocol_version,omitempty" mapstructure:"ssl_max_protocol_version,omitempty"`

	// Sets the minimum SSL/TLS protocol version to use.
	SslMinProtocolVersion string `json:"ssl_min_protocol_version,omitempty" yaml:"ssl_min_protocol_version,omitempty" mapstructure:"ssl_min_protocol_version,omitempty"`

	// Command to obtain passphrases for SSL.
	SslPassphraseCommand *string `json:"ssl_passphrase_command,omitempty" yaml:"ssl_passphrase_command,omitempty" mapstructure:"ssl_passphrase_command,omitempty"`

	// Controls whether "ssl_passphrase_command" is called during server reload.
	SslPassphraseCommandSupportsReload bool `json:"ssl_passphrase_command_supports_reload,omitempty" yaml:"ssl_passphrase_command_supports_reload,omitempty" mapstructure:"ssl_passphrase_command_supports_reload,omitempty"`

	// Give priority to server ciphersuite order.
	SslPreferServerCiphers bool `json:"ssl_prefer_server_ciphers,omitempty" yaml:"ssl_prefer_server_ciphers,omitempty" mapstructure:"ssl_prefer_server_ciphers,omitempty"`

	// Causes '...' strings to treat backslashes literally.
	StandardConformingStrings bool `json:"standard_conforming_strings,omitempty" yaml:"standard_conforming_strings,omitempty" mapstructure:"standard_conforming_strings,omitempty"`

	// Sets the maximum allowed duration of any statement. A value of 0 turns off the
	// timeout.
	StatementTimeout *types.Duration `json:"statement_timeout,omitempty" yaml:"statement_timeout,omitempty" mapstructure:"statement_timeout,omitempty"`

	// Sets the consistency of accesses to statistics data.
	StatsFetchConsistency string `json:"stats_fetch_consistency,omitempty" yaml:"stats_fetch_consistency,omitempty" mapstructure:"stats_fetch_consistency,omitempty"`

	// Sets the size of the dedicated buffer pool used for the subtransaction cache.
	// Specify 0 to have this value determined as a fraction of shared_buffers.
	SubtransactionBuffers *types.Size `json:"subtransaction_buffers,omitempty" yaml:"subtransaction_buffers,omitempty" mapstructure:"subtransaction_buffers,omitempty"`

	// Starts the WAL summarizer process to enable incremental backup.
	SummarizeWal bool `json:"summarize_wal,omitempty" yaml:"summarize_wal,omitempty" mapstructure:"summarize_wal,omitempty"`

	// Sets the number of connection slots reserved for superusers.
	SuperuserReservedConnections int `json:"superuser_reserved_connections,omitempty" yaml:"superuser_reserved_connections,omitempty" mapstructure:"superuser_reserved_connections,omitempty"`

	// Enables a physical standby to synchronize logical failover replication slots
	// from the primary server.
	SyncReplicationSlots bool `json:"sync_replication_slots,omitempty" yaml:"sync_replication_slots,omitempty" mapstructure:"sync_replication_slots,omitempty"`

	// Enable synchronized sequential scans.
	SynchronizeSeqscans bool `json:"synchronize_seqscans,omitempty" yaml:"synchronize_seqscans,omitempty" mapstructure:"synchronize_seqscans,omitempty"`

	// Lists streaming replication standby server replication slot names that logical
	// WAL sender processes will wait for. Logical WAL sender processes will send
	// decoded changes to output plugins only after the specified replication slots
	// have confirmed receiving WAL.
	SynchronizedStandbySlots *string `json:"synchronized_standby_slots,omitempty" yaml:"synchronized_standby_slots,omitempty" mapstructure:"synchronized_standby_slots,omitempty"`

	// Sets the current transaction's synchronization level.
	SynchronousCommit PostgresConfSynchronousCommit `json:"synchronous_commit,omitempty" yaml:"synchronous_commit,omitempty" mapstructure:"synchronous_commit,omitempty"`

	// Number of synchronous standbys and list of names of potential synchronous ones.
	SynchronousStandbyNames *string `json:"synchronous_standby_names,omitempty" yaml:"synchronous_standby_names,omitempty" mapstructure:"synchronous_standby_names,omitempty"`

	// Sets the syslog "facility" to be used when syslog enabled.
	SyslogFacility PostgresConfSyslogFacility `json:"syslog_facility,omitempty" yaml:"syslog_facility,omitempty" mapstructure:"syslog_facility,omitempty"`

	// Sets the program name used to identify PostgreSQL messages in syslog.
	SyslogIdent string `json:"syslog_ident,omitempty" yaml:"syslog_ident,omitempty" mapstructure:"syslog_ident,omitempty"`

	// Add sequence number to syslog messages to avoid duplicate suppression.
	SyslogSequenceNumbers bool `json:"syslog_sequence_numbers,omitempty" yaml:"syslog_sequence_numbers,omitempty" mapstructure:"syslog_sequence_numbers,omitempty"`

	// Split messages sent to syslog by lines and to fit into 1024 bytes.
	SyslogSplitMessages bool `json:"syslog_split_messages,omitempty" yaml:"syslog_split_messages,omitempty" mapstructure:"syslog_split_messages,omitempty"`

	// Maximum number of TCP keepalive retransmits. Number of consecutive keepalive
	// retransmits that can be lost before a connection is considered dead. A value of
	// 0 uses the system default.
	TcpKeepalivesCount int `json:"tcp_keepalives_count,omitempty" yaml:"tcp_keepalives_count,omitempty" mapstructure:"tcp_keepalives_count,omitempty"`

	// Time between issuing TCP keepalives. A value of 0 uses the system default.
	TcpKeepalivesIdle int `json:"tcp_keepalives_idle,omitempty" yaml:"tcp_keepalives_idle,omitempty" mapstructure:"tcp_keepalives_idle,omitempty"`

	// Time between TCP keepalive retransmits. A value of 0 uses the system default.
	TcpKeepalivesInterval int `json:"tcp_keepalives_interval,omitempty" yaml:"tcp_keepalives_interval,omitempty" mapstructure:"tcp_keepalives_interval,omitempty"`

	// TCP user timeout. A value of 0 uses the system default.
	TcpUserTimeout *types.Duration `json:"tcp_user_timeout,omitempty" yaml:"tcp_user_timeout,omitempty" mapstructure:"tcp_user_timeout,omitempty"`

	// Sets the maximum number of temporary buffers used by each session.
	TempBuffers *types.Size `json:"temp_buffers,omitempty" yaml:"temp_buffers,omitempty" mapstructure:"temp_buffers,omitempty"`

	// Limits the total size of all temporary files used by each process. -1 means no
	// limit.
	TempFileLimit *types.Size `json:"temp_file_limit,omitempty" yaml:"temp_file_limit,omitempty" mapstructure:"temp_file_limit,omitempty"`

	// Sets the tablespace(s) to use for temporary tables and sort files.
	TempTablespaces *string `json:"temp_tablespaces,omitempty" yaml:"temp_tablespaces,omitempty" mapstructure:"temp_tablespaces,omitempty"`

	// Selects a file of time zone abbreviations.
	TimezoneAbbreviations *string `json:"timezone_abbreviations,omitempty" yaml:"timezone_abbreviations,omitempty" mapstructure:"timezone_abbreviations,omitempty"`

	// Collects information about executing commands. Enables the collection of
	// information on the currently executing command of each session, along with the
	// time at which that command began execution.
	TrackActivities bool `json:"track_activities,omitempty" yaml:"track_activities,omitempty" mapstructure:"track_activities,omitempty"`

	// Sets the size reserved for pg_stat_activity.query, in bytes.
	TrackActivityQuerySize int `json:"track_activity_query_size,omitempty" yaml:"track_activity_query_size,omitempty" mapstructure:"track_activity_query_size,omitempty"`

	// Collects transaction commit time.
	TrackCommitTimestamp bool `json:"track_commit_timestamp,omitempty" yaml:"track_commit_timestamp,omitempty" mapstructure:"track_commit_timestamp,omitempty"`

	// Collects statistics on database activity.
	TrackCounts bool `json:"track_counts,omitempty" yaml:"track_counts,omitempty" mapstructure:"track_counts,omitempty"`

	// Collects function-level statistics on database activity.
	TrackFunctions string `json:"track_functions,omitempty" yaml:"track_functions,omitempty" mapstructure:"track_functions,omitempty"`

	// Collects timing statistics for database I/O activity.
	TrackIoTiming bool `json:"track_io_timing,omitempty" yaml:"track_io_timing,omitempty" mapstructure:"track_io_timing,omitempty"`

	// Collects timing statistics for WAL I/O activity.
	TrackWalIoTiming bool `json:"track_wal_io_timing,omitempty" yaml:"track_wal_io_timing,omitempty" mapstructure:"track_wal_io_timing,omitempty"`

	// Sets the size of the dedicated buffer pool used for the transaction status
	// cache. Specify 0 to have this value determined as a fraction of shared_buffers.
	TransactionBuffers *types.Size `json:"transaction_buffers,omitempty" yaml:"transaction_buffers,omitempty" mapstructure:"transaction_buffers,omitempty"`

	// Sets the maximum allowed duration of any transaction within a session (not a
	// prepared transaction). A value of 0 turns off the timeout.
	TransactionTimeout *types.Duration `json:"transaction_timeout,omitempty" yaml:"transaction_timeout,omitempty" mapstructure:"transaction_timeout,omitempty"`

	// Treats "expr=NULL" as "expr IS NULL". When turned on, expressions of the form
	// expr = NULL (or NULL = expr) are treated as expr IS NULL, that is, they return
	// true if expr evaluates to the null value, and false otherwise. The correct
	// behavior of expr = NULL is to always return null (unknown).
	TransformNullEquals bool `json:"transform_null_equals,omitempty" yaml:"transform_null_equals,omitempty" mapstructure:"transform_null_equals,omitempty"`

	// Sets the directories where Unix-domain sockets will be created.
	UnixSocketDirectories string `json:"unix_socket_directories,omitempty" yaml:"unix_socket_directories,omitempty" mapstructure:"unix_socket_directories,omitempty"`

	// Sets the owning group of the Unix-domain socket. The owning user of the socket
	// is always the user that starts the server.
	UnixSocketGroup *string `json:"unix_socket_group,omitempty" yaml:"unix_socket_group,omitempty" mapstructure:"unix_socket_group,omitempty"`

	// Sets the access permissions of the Unix-domain socket. Unix-domain sockets use
	// the usual Unix file system permission set. The parameter value is expected to
	// be a numeric mode specification in the form accepted by the chmod and umask
	// system calls. (To use the customary octal format the number must start with a 0
	// (zero).)
	UnixSocketPermissions int `json:"unix_socket_permissions,omitempty" yaml:"unix_socket_permissions,omitempty" mapstructure:"unix_socket_permissions,omitempty"`

	// Updates the process title to show the active SQL command. Enables updating of
	// the process title every time a new SQL command is received by the server.
	UpdateProcessTitle bool `json:"update_process_title,omitempty" yaml:"update_process_title,omitempty" mapstructure:"update_process_title,omitempty"`

	// Sets the buffer pool size for VACUUM, ANALYZE, and autovacuum.
	VacuumBufferUsageLimit *types.Size `json:"vacuum_buffer_usage_limit,omitempty" yaml:"vacuum_buffer_usage_limit,omitempty" mapstructure:"vacuum_buffer_usage_limit,omitempty"`

	// Vacuum cost delay in milliseconds.
	VacuumCostDelay *types.Duration `json:"vacuum_cost_delay,omitempty" yaml:"vacuum_cost_delay,omitempty" mapstructure:"vacuum_cost_delay,omitempty"`

	// Vacuum cost amount available before napping.
	VacuumCostLimit int `json:"vacuum_cost_limit,omitempty" yaml:"vacuum_cost_limit,omitempty" mapstructure:"vacuum_cost_limit,omitempty"`

	// Vacuum cost for a page dirtied by vacuum.
	VacuumCostPageDirty int `json:"vacuum_cost_page_dirty,omitempty" yaml:"vacuum_cost_page_dirty,omitempty" mapstructure:"vacuum_cost_page_dirty,omitempty"`

	// Vacuum cost for a page found in the buffer cache.
	VacuumCostPageHit *types.Size `json:"vacuum_cost_page_hit,omitempty" yaml:"vacuum_cost_page_hit,omitempty" mapstructure:"vacuum_cost_page_hit,omitempty"`

	// Vacuum cost for a page not found in the buffer cache.
	VacuumCostPageMiss *types.Size `json:"vacuum_cost_page_miss,omitempty" yaml:"vacuum_cost_page_miss,omitempty" mapstructure:"vacuum_cost_page_miss,omitempty"`

	// Age at which VACUUM should trigger failsafe to avoid a wraparound outage.
	VacuumFailsafeAge int `json:"vacuum_failsafe_age,omitempty" yaml:"vacuum_failsafe_age,omitempty" mapstructure:"vacuum_failsafe_age,omitempty"`

	// Minimum age at which VACUUM should freeze a table row.
	VacuumFreezeMinAge int `json:"vacuum_freeze_min_age,omitempty" yaml:"vacuum_freeze_min_age,omitempty" mapstructure:"vacuum_freeze_min_age,omitempty"`

	// Age at which VACUUM should scan whole table to freeze tuples.
	VacuumFreezeTableAge int `json:"vacuum_freeze_table_age,omitempty" yaml:"vacuum_freeze_table_age,omitempty" mapstructure:"vacuum_freeze_table_age,omitempty"`

	// Multixact age at which VACUUM should trigger failsafe to avoid a wraparound
	// outage.
	VacuumMultixactFailsafeAge int `json:"vacuum_multixact_failsafe_age,omitempty" yaml:"vacuum_multixact_failsafe_age,omitempty" mapstructure:"vacuum_multixact_failsafe_age,omitempty"`

	// Minimum age at which VACUUM should freeze a MultiXactId in a table row.
	VacuumMultixactFreezeMinAge int `json:"vacuum_multixact_freeze_min_age,omitempty" yaml:"vacuum_multixact_freeze_min_age,omitempty" mapstructure:"vacuum_multixact_freeze_min_age,omitempty"`

	// Multixact age at which VACUUM should scan whole table to freeze tuples.
	VacuumMultixactFreezeTableAge int `json:"vacuum_multixact_freeze_table_age,omitempty" yaml:"vacuum_multixact_freeze_table_age,omitempty" mapstructure:"vacuum_multixact_freeze_table_age,omitempty"`

	// Sets the number of disk-page buffers in shared memory for WAL. Specify -1 to
	// have this value determined as a fraction of shared_buffers.
	WalBuffers *types.Size `json:"wal_buffers,omitempty" yaml:"wal_buffers,omitempty" mapstructure:"wal_buffers,omitempty"`

	// Compresses full-page writes written in WAL file with specified method.
	WalCompression PostgresConfWalCompression `json:"wal_compression,omitempty" yaml:"wal_compression,omitempty" mapstructure:"wal_compression,omitempty"`

	// Buffer size for reading ahead in the WAL during recovery. Maximum distance to
	// read ahead in the WAL to prefetch referenced data blocks.
	WalDecodeBufferSize *types.Size `json:"wal_decode_buffer_size,omitempty" yaml:"wal_decode_buffer_size,omitempty" mapstructure:"wal_decode_buffer_size,omitempty"`

	// Writes zeroes to new WAL files before first use.
	WalInitZero bool `json:"wal_init_zero,omitempty" yaml:"wal_init_zero,omitempty" mapstructure:"wal_init_zero,omitempty"`

	// Sets the size of WAL files held for standby servers.
	WalKeepSize *types.Size `json:"wal_keep_size,omitempty" yaml:"wal_keep_size,omitempty" mapstructure:"wal_keep_size,omitempty"`

	// Sets the level of information written to the WAL.
	WalLevel PostgresConfWalLevel `json:"wal_level,omitempty" yaml:"wal_level,omitempty" mapstructure:"wal_level,omitempty"`

	// Writes full pages to WAL when first modified after a checkpoint, even for a
	// non-critical modification.
	WalLogHints bool `json:"wal_log_hints,omitempty" yaml:"wal_log_hints,omitempty" mapstructure:"wal_log_hints,omitempty"`

	// Sets whether a WAL receiver should create a temporary replication slot if no
	// permanent slot is configured.
	WalReceiverCreateTempSlot bool `json:"wal_receiver_create_temp_slot,omitempty" yaml:"wal_receiver_create_temp_slot,omitempty" mapstructure:"wal_receiver_create_temp_slot,omitempty"`

	// Sets the maximum interval between WAL receiver status reports to the sending
	// server.
	WalReceiverStatusInterval int `json:"wal_receiver_status_interval,omitempty" yaml:"wal_receiver_status_interval,omitempty" mapstructure:"wal_receiver_status_interval,omitempty"`

	// Sets the maximum wait time to receive data from the sending server.
	WalReceiverTimeout *types.Duration `json:"wal_receiver_timeout,omitempty" yaml:"wal_receiver_timeout,omitempty" mapstructure:"wal_receiver_timeout,omitempty"`

	// Recycles WAL files by renaming them.
	WalRecycle bool `json:"wal_recycle,omitempty" yaml:"wal_recycle,omitempty" mapstructure:"wal_recycle,omitempty"`

	// Sets the time to wait before retrying to retrieve WAL after a failed attempt.
	WalRetrieveRetryInterval int `json:"wal_retrieve_retry_interval,omitempty" yaml:"wal_retrieve_retry_interval,omitempty" mapstructure:"wal_retrieve_retry_interval,omitempty"`

	// Sets the maximum time to wait for WAL replication.
	WalSenderTimeout *types.Duration `json:"wal_sender_timeout,omitempty" yaml:"wal_sender_timeout,omitempty" mapstructure:"wal_sender_timeout,omitempty"`

	// Minimum size of new file to fsync instead of writing WAL.
	WalSkipThreshold *types.Size `json:"wal_skip_threshold,omitempty" yaml:"wal_skip_threshold,omitempty" mapstructure:"wal_skip_threshold,omitempty"`

	// Time for which WAL summary files should be kept.
	WalSummaryKeepTime int `json:"wal_summary_keep_time,omitempty" yaml:"wal_summary_keep_time,omitempty" mapstructure:"wal_summary_keep_time,omitempty"`

	// Selects the method used for forcing WAL updates to disk.
	WalSyncMethod string `json:"wal_sync_method,omitempty" yaml:"wal_sync_method,omitempty" mapstructure:"wal_sync_method,omitempty"`

	// Time between WAL flushes performed in the WAL writer.
	WalWriterDelay int `json:"wal_writer_delay,omitempty" yaml:"wal_writer_delay,omitempty" mapstructure:"wal_writer_delay,omitempty"`

	// Amount of WAL written out by WAL writer that triggers a flush.
	WalWriterFlushAfter int `json:"wal_writer_flush_after,omitempty" yaml:"wal_writer_flush_after,omitempty" mapstructure:"wal_writer_flush_after,omitempty"`

	// Sets the maximum memory to be used for query workspaces. This much memory can
	// be used by each internal sort operation and hash table before switching to
	// temporary disk files.
	WorkMem *types.Size `json:"work_mem,omitempty" yaml:"work_mem,omitempty" mapstructure:"work_mem,omitempty"`

	// Sets how binary values are to be encoded in XML.
	Xmlbinary string `json:"xmlbinary,omitempty" yaml:"xmlbinary,omitempty" mapstructure:"xmlbinary,omitempty"`

	// Sets whether XML data in implicit parsing and serialization operations is to be
	// considered as documents or content fragments.
	Xmloption string `json:"xmloption,omitempty" yaml:"xmloption,omitempty" mapstructure:"xmloption,omitempty"`
}

type PostgresConfArchiveMode string

const PostgresConfArchiveModeAlways PostgresConfArchiveMode = "always"
const PostgresConfArchiveModeOff PostgresConfArchiveMode = "off"
const PostgresConfArchiveModeOn PostgresConfArchiveMode = "on"

var enumValues_PostgresConfArchiveMode = []interface{}{
	"off",
	"on",
	"always",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfArchiveMode) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfArchiveMode {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfArchiveMode, v)
	}
	*j = PostgresConfArchiveMode(v)
	return nil
}

type PostgresConfClientMinMessages string

const PostgresConfClientMinMessagesDebug1 PostgresConfClientMinMessages = "debug1"
const PostgresConfClientMinMessagesDebug2 PostgresConfClientMinMessages = "debug2"
const PostgresConfClientMinMessagesDebug3 PostgresConfClientMinMessages = "debug3"
const PostgresConfClientMinMessagesDebug4 PostgresConfClientMinMessages = "debug4"
const PostgresConfClientMinMessagesDebug5 PostgresConfClientMinMessages = "debug5"
const PostgresConfClientMinMessagesError PostgresConfClientMinMessages = "error"
const PostgresConfClientMinMessagesLog PostgresConfClientMinMessages = "log"
const PostgresConfClientMinMessagesNotice PostgresConfClientMinMessages = "notice"
const PostgresConfClientMinMessagesWarning PostgresConfClientMinMessages = "warning"

var enumValues_PostgresConfClientMinMessages = []interface{}{
	"debug5",
	"debug4",
	"debug3",
	"debug2",
	"debug1",
	"log",
	"notice",
	"warning",
	"error",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfClientMinMessages) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfClientMinMessages {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfClientMinMessages, v)
	}
	*j = PostgresConfClientMinMessages(v)
	return nil
}

type PostgresConfComputeQueryId string

const PostgresConfComputeQueryIdOff PostgresConfComputeQueryId = "off"
const PostgresConfComputeQueryIdOn PostgresConfComputeQueryId = "on"

var enumValues_PostgresConfComputeQueryId = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfComputeQueryId) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfComputeQueryId {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfComputeQueryId, v)
	}
	*j = PostgresConfComputeQueryId(v)
	return nil
}

type PostgresConfConstraintExclusion string

const PostgresConfConstraintExclusionOff PostgresConfConstraintExclusion = "off"
const PostgresConfConstraintExclusionOn PostgresConfConstraintExclusion = "on"

var enumValues_PostgresConfConstraintExclusion = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfConstraintExclusion) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfConstraintExclusion {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfConstraintExclusion, v)
	}
	*j = PostgresConfConstraintExclusion(v)
	return nil
}

type PostgresConfDefaultTransactionIsolation string

const PostgresConfDefaultTransactionIsolationReadCommitted PostgresConfDefaultTransactionIsolation = "read committed"
const PostgresConfDefaultTransactionIsolationReadUncommitted PostgresConfDefaultTransactionIsolation = "read uncommitted"
const PostgresConfDefaultTransactionIsolationRepeatableRead PostgresConfDefaultTransactionIsolation = "repeatable read"
const PostgresConfDefaultTransactionIsolationSerializable PostgresConfDefaultTransactionIsolation = "serializable"

var enumValues_PostgresConfDefaultTransactionIsolation = []interface{}{
	"serializable",
	"repeatable read",
	"read committed",
	"read uncommitted",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfDefaultTransactionIsolation) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfDefaultTransactionIsolation {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfDefaultTransactionIsolation, v)
	}
	*j = PostgresConfDefaultTransactionIsolation(v)
	return nil
}

type PostgresConfLogMinMessages string

const PostgresConfLogMinMessagesDebug1 PostgresConfLogMinMessages = "debug1"
const PostgresConfLogMinMessagesDebug2 PostgresConfLogMinMessages = "debug2"
const PostgresConfLogMinMessagesDebug3 PostgresConfLogMinMessages = "debug3"
const PostgresConfLogMinMessagesDebug4 PostgresConfLogMinMessages = "debug4"
const PostgresConfLogMinMessagesDebug5 PostgresConfLogMinMessages = "debug5"
const PostgresConfLogMinMessagesError PostgresConfLogMinMessages = "error"
const PostgresConfLogMinMessagesFatal PostgresConfLogMinMessages = "fatal"
const PostgresConfLogMinMessagesInfo PostgresConfLogMinMessages = "info"
const PostgresConfLogMinMessagesLog PostgresConfLogMinMessages = "log"
const PostgresConfLogMinMessagesNotice PostgresConfLogMinMessages = "notice"
const PostgresConfLogMinMessagesPanic PostgresConfLogMinMessages = "panic"
const PostgresConfLogMinMessagesWarning PostgresConfLogMinMessages = "warning"

var enumValues_PostgresConfLogMinMessages = []interface{}{
	"debug5",
	"debug4",
	"debug3",
	"debug2",
	"debug1",
	"info",
	"notice",
	"warning",
	"error",
	"log",
	"fatal",
	"panic",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfLogMinMessages) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfLogMinMessages {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfLogMinMessages, v)
	}
	*j = PostgresConfLogMinMessages(v)
	return nil
}

type PostgresConfLogStatement string

const PostgresConfLogStatementAll PostgresConfLogStatement = "all"
const PostgresConfLogStatementDdl PostgresConfLogStatement = "ddl"
const PostgresConfLogStatementMod PostgresConfLogStatement = "mod"
const PostgresConfLogStatementNone PostgresConfLogStatement = "none"

var enumValues_PostgresConfLogStatement = []interface{}{
	"none",
	"ddl",
	"mod",
	"all",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfLogStatement) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfLogStatement {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfLogStatement, v)
	}
	*j = PostgresConfLogStatement(v)
	return nil
}

type PostgresConfPasswordEncryption string

const PostgresConfPasswordEncryptionMd5 PostgresConfPasswordEncryption = "md5"
const PostgresConfPasswordEncryptionScramSha256 PostgresConfPasswordEncryption = "scram-sha-256"

var enumValues_PostgresConfPasswordEncryption = []interface{}{
	"md5",
	"scram-sha-256",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfPasswordEncryption) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfPasswordEncryption {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfPasswordEncryption, v)
	}
	*j = PostgresConfPasswordEncryption(v)
	return nil
}

type PostgresConfSynchronousCommit string

const PostgresConfSynchronousCommitLocal PostgresConfSynchronousCommit = "local"
const PostgresConfSynchronousCommitOff PostgresConfSynchronousCommit = "off"
const PostgresConfSynchronousCommitOn PostgresConfSynchronousCommit = "on"
const PostgresConfSynchronousCommitRemoteApply PostgresConfSynchronousCommit = "remote_apply"
const PostgresConfSynchronousCommitRemoteWrite PostgresConfSynchronousCommit = "remote_write"

var enumValues_PostgresConfSynchronousCommit = []interface{}{
	"off",
	"local",
	"remote_write",
	"remote_apply",
	"on",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfSynchronousCommit) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfSynchronousCommit {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfSynchronousCommit, v)
	}
	*j = PostgresConfSynchronousCommit(v)
	return nil
}

type PostgresConfSyslogFacility string

const PostgresConfSyslogFacilityOff PostgresConfSyslogFacility = "off"
const PostgresConfSyslogFacilityOn PostgresConfSyslogFacility = "on"

var enumValues_PostgresConfSyslogFacility = []interface{}{
	"on",
	"off",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfSyslogFacility) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfSyslogFacility {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfSyslogFacility, v)
	}
	*j = PostgresConfSyslogFacility(v)
	return nil
}

type PostgresConfWalCompression string

const PostgresConfWalCompressionLz4 PostgresConfWalCompression = "lz4"
const PostgresConfWalCompressionOff PostgresConfWalCompression = "off"
const PostgresConfWalCompressionOn PostgresConfWalCompression = "on"
const PostgresConfWalCompressionPglz PostgresConfWalCompression = "pglz"
const PostgresConfWalCompressionZstd PostgresConfWalCompression = "zstd"

var enumValues_PostgresConfWalCompression = []interface{}{
	"off",
	"on",
	"pglz",
	"lz4",
	"zstd",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfWalCompression) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfWalCompression {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfWalCompression, v)
	}
	*j = PostgresConfWalCompression(v)
	return nil
}

type PostgresConfWalLevel string

const PostgresConfWalLevelLogical PostgresConfWalLevel = "logical"
const PostgresConfWalLevelMinimal PostgresConfWalLevel = "minimal"
const PostgresConfWalLevelReplica PostgresConfWalLevel = "replica"

var enumValues_PostgresConfWalLevel = []interface{}{
	"minimal",
	"replica",
	"logical",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConfWalLevel) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgresConfWalLevel {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgresConfWalLevel, v)
	}
	*j = PostgresConfWalLevel(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgresConf) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain PostgresConf
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["DateStyle"]; !ok || v == nil {
		plain.DateStyle = "ISO, MDY"
	}
	if v, ok := raw["IntervalStyle"]; !ok || v == nil {
		plain.IntervalStyle = "postgres"
	}
	if v, ok := raw["TimeZone"]; !ok || v == nil {
		plain.TimeZone = "GMT"
	}
	if v, ok := raw["allow_alter_system"]; !ok || v == nil {
		plain.AllowAlterSystem = false
	}
	if v, ok := raw["archive_mode"]; !ok || v == nil {
		plain.ArchiveMode = "off"
	}
	if v, ok := raw["archive_timeout"]; !ok || v == nil {
		plain.ArchiveTimeout = 0.0
	}
	if 1073741823 < plain.ArchiveTimeout {
		return fmt.Errorf("field %s: must be <= %v", "archive_timeout", 1073741823)
	}
	if v, ok := raw["array_nulls"]; !ok || v == nil {
		plain.ArrayNulls = false
	}
	if v, ok := raw["authentication_timeout"]; !ok || v == nil {
		plain.AuthenticationTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.AuthenticationTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "AuthenticationTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["autovacuum"]; !ok || v == nil {
		plain.Autovacuum = false
	}
	if v, ok := raw["autovacuum_analyze_scale_factor"]; !ok || v == nil {
		plain.AutovacuumAnalyzeScaleFactor = 0.0
	}
	if 100 < plain.AutovacuumAnalyzeScaleFactor {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_analyze_scale_factor", 100)
	}
	if v, ok := raw["autovacuum_analyze_threshold"]; !ok || v == nil {
		plain.AutovacuumAnalyzeThreshold = 0.0
	}
	if 2147483647 < plain.AutovacuumAnalyzeThreshold {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_analyze_threshold", 2147483647)
	}
	if v, ok := raw["autovacuum_freeze_max_age"]; !ok || v == nil {
		plain.AutovacuumFreezeMaxAge = 0.0
	}
	if 2000000000 < plain.AutovacuumFreezeMaxAge {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_freeze_max_age", 2000000000)
	}
	if 100000 > plain.AutovacuumFreezeMaxAge {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_freeze_max_age", 100000)
	}
	if v, ok := raw["autovacuum_max_workers"]; !ok || v == nil {
		plain.AutovacuumMaxWorkers = 0.0
	}
	if 262143 < plain.AutovacuumMaxWorkers {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_max_workers", 262143)
	}
	if 1 > plain.AutovacuumMaxWorkers {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_max_workers", 1)
	}
	if v, ok := raw["autovacuum_multixact_freeze_max_age"]; !ok || v == nil {
		plain.AutovacuumMultixactFreezeMaxAge = 0.0
	}
	if 2000000000 < plain.AutovacuumMultixactFreezeMaxAge {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_multixact_freeze_max_age", 2000000000)
	}
	if 10000 > plain.AutovacuumMultixactFreezeMaxAge {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_multixact_freeze_max_age", 10000)
	}
	if v, ok := raw["autovacuum_naptime"]; !ok || v == nil {
		plain.AutovacuumNaptime = 0.0
	}
	if 2147483 < plain.AutovacuumNaptime {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_naptime", 2147483)
	}
	if 1 > plain.AutovacuumNaptime {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_naptime", 1)
	}
	if v, ok := raw["autovacuum_vacuum_cost_delay"]; !ok || v == nil {
		plain.AutovacuumVacuumCostDelay = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.AutovacuumVacuumCostDelay)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "AutovacuumVacuumCostDelay", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["autovacuum_vacuum_cost_limit"]; !ok || v == nil {
		plain.AutovacuumVacuumCostLimit = 0.0
	}
	if 10000 < plain.AutovacuumVacuumCostLimit {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_vacuum_cost_limit", 10000)
	}
	if -1 > plain.AutovacuumVacuumCostLimit {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_vacuum_cost_limit", -1)
	}
	if v, ok := raw["autovacuum_vacuum_insert_scale_factor"]; !ok || v == nil {
		plain.AutovacuumVacuumInsertScaleFactor = 0.0
	}
	if 100 < plain.AutovacuumVacuumInsertScaleFactor {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_vacuum_insert_scale_factor", 100)
	}
	if v, ok := raw["autovacuum_vacuum_insert_threshold"]; !ok || v == nil {
		plain.AutovacuumVacuumInsertThreshold = 0.0
	}
	if 2147483647 < plain.AutovacuumVacuumInsertThreshold {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_vacuum_insert_threshold", 2147483647)
	}
	if -1 > plain.AutovacuumVacuumInsertThreshold {
		return fmt.Errorf("field %s: must be >= %v", "autovacuum_vacuum_insert_threshold", -1)
	}
	if v, ok := raw["autovacuum_vacuum_scale_factor"]; !ok || v == nil {
		plain.AutovacuumVacuumScaleFactor = 0.0
	}
	if 100 < plain.AutovacuumVacuumScaleFactor {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_vacuum_scale_factor", 100)
	}
	if v, ok := raw["autovacuum_vacuum_threshold"]; !ok || v == nil {
		plain.AutovacuumVacuumThreshold = 0.0
	}
	if 2147483647 < plain.AutovacuumVacuumThreshold {
		return fmt.Errorf("field %s: must be <= %v", "autovacuum_vacuum_threshold", 2147483647)
	}
	if v, ok := raw["autovacuum_work_mem"]; !ok || v == nil {
		plain.AutovacuumWorkMem = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.AutovacuumWorkMem)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "AutovacuumWorkMem", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["backend_flush_after"]; !ok || v == nil {
		plain.BackendFlushAfter = 0.0
	}
	if 256 < plain.BackendFlushAfter {
		return fmt.Errorf("field %s: must be <= %v", "backend_flush_after", 256)
	}
	if v, ok := raw["backslash_quote"]; !ok || v == nil {
		plain.BackslashQuote = "safe_encoding"
	}
	if v, ok := raw["bgwriter_delay"]; !ok || v == nil {
		plain.BgwriterDelay = 0.0
	}
	if 10000 < plain.BgwriterDelay {
		return fmt.Errorf("field %s: must be <= %v", "bgwriter_delay", 10000)
	}
	if 10 > plain.BgwriterDelay {
		return fmt.Errorf("field %s: must be >= %v", "bgwriter_delay", 10)
	}
	if v, ok := raw["bgwriter_flush_after"]; !ok || v == nil {
		plain.BgwriterFlushAfter = 0.0
	}
	if 256 < plain.BgwriterFlushAfter {
		return fmt.Errorf("field %s: must be <= %v", "bgwriter_flush_after", 256)
	}
	if v, ok := raw["bgwriter_lru_maxpages"]; !ok || v == nil {
		plain.BgwriterLruMaxpages = 0.0
	}
	if 1073741823 < plain.BgwriterLruMaxpages {
		return fmt.Errorf("field %s: must be <= %v", "bgwriter_lru_maxpages", 1073741823)
	}
	if v, ok := raw["bgwriter_lru_multiplier"]; !ok || v == nil {
		plain.BgwriterLruMultiplier = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.BgwriterLruMultiplier)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "BgwriterLruMultiplier", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["bonjour"]; !ok || v == nil {
		plain.Bonjour = false
	}
	if v, ok := raw["bytea_output"]; !ok || v == nil {
		plain.ByteaOutput = "hex"
	}
	if v, ok := raw["check_function_bodies"]; !ok || v == nil {
		plain.CheckFunctionBodies = false
	}
	if v, ok := raw["checkpoint_completion_target"]; !ok || v == nil {
		plain.CheckpointCompletionTarget = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.CheckpointCompletionTarget)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "CheckpointCompletionTarget", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["checkpoint_flush_after"]; !ok || v == nil {
		plain.CheckpointFlushAfter = 0.0
	}
	if 256 < plain.CheckpointFlushAfter {
		return fmt.Errorf("field %s: must be <= %v", "checkpoint_flush_after", 256)
	}
	if v, ok := raw["checkpoint_timeout"]; !ok || v == nil {
		plain.CheckpointTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.CheckpointTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "CheckpointTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["checkpoint_warning"]; !ok || v == nil {
		plain.CheckpointWarning = 0.0
	}
	if 2147483647 < plain.CheckpointWarning {
		return fmt.Errorf("field %s: must be <= %v", "checkpoint_warning", 2147483647)
	}
	if v, ok := raw["client_connection_check_interval"]; !ok || v == nil {
		plain.ClientConnectionCheckInterval = 0.0
	}
	if 2147483647 < plain.ClientConnectionCheckInterval {
		return fmt.Errorf("field %s: must be <= %v", "client_connection_check_interval", 2147483647)
	}
	if v, ok := raw["client_encoding"]; !ok || v == nil {
		plain.ClientEncoding = "SQL_ASCII"
	}
	if v, ok := raw["client_min_messages"]; !ok || v == nil {
		plain.ClientMinMessages = "notice"
	}
	if v, ok := raw["commit_delay"]; !ok || v == nil {
		plain.CommitDelay = 0.0
	}
	if 100000 < plain.CommitDelay {
		return fmt.Errorf("field %s: must be <= %v", "commit_delay", 100000)
	}
	if v, ok := raw["commit_siblings"]; !ok || v == nil {
		plain.CommitSiblings = 0.0
	}
	if 1000 < plain.CommitSiblings {
		return fmt.Errorf("field %s: must be <= %v", "commit_siblings", 1000)
	}
	if v, ok := raw["commit_timestamp_buffers"]; !ok || v == nil {
		plain.CommitTimestampBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.CommitTimestampBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "CommitTimestampBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["compute_query_id"]; !ok || v == nil {
		plain.ComputeQueryId = "auto"
	}
	if v, ok := raw["constraint_exclusion"]; !ok || v == nil {
		plain.ConstraintExclusion = "partition"
	}
	if v, ok := raw["cpu_index_tuple_cost"]; !ok || v == nil {
		plain.CpuIndexTupleCost = 0.0
	}
	if 1.79769e+308 < plain.CpuIndexTupleCost {
		return fmt.Errorf("field %s: must be <= %v", "cpu_index_tuple_cost", 1.79769e+308)
	}
	if v, ok := raw["cpu_operator_cost"]; !ok || v == nil {
		plain.CpuOperatorCost = 0.0
	}
	if 1.79769e+308 < plain.CpuOperatorCost {
		return fmt.Errorf("field %s: must be <= %v", "cpu_operator_cost", 1.79769e+308)
	}
	if v, ok := raw["cpu_tuple_cost"]; !ok || v == nil {
		plain.CpuTupleCost = 0.0
	}
	if 1.79769e+308 < plain.CpuTupleCost {
		return fmt.Errorf("field %s: must be <= %v", "cpu_tuple_cost", 1.79769e+308)
	}
	if v, ok := raw["cursor_tuple_fraction"]; !ok || v == nil {
		plain.CursorTupleFraction = 0.0
	}
	if 1 < plain.CursorTupleFraction {
		return fmt.Errorf("field %s: must be <= %v", "cursor_tuple_fraction", 1)
	}
	if v, ok := raw["data_sync_retry"]; !ok || v == nil {
		plain.DataSyncRetry = false
	}
	if v, ok := raw["deadlock_timeout"]; !ok || v == nil {
		plain.DeadlockTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.DeadlockTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "DeadlockTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["debug_pretty_print"]; !ok || v == nil {
		plain.DebugPrettyPrint = false
	}
	if v, ok := raw["debug_print_parse"]; !ok || v == nil {
		plain.DebugPrintParse = false
	}
	if v, ok := raw["debug_print_plan"]; !ok || v == nil {
		plain.DebugPrintPlan = false
	}
	if v, ok := raw["debug_print_rewritten"]; !ok || v == nil {
		plain.DebugPrintRewritten = false
	}
	if v, ok := raw["default_statistics_target"]; !ok || v == nil {
		plain.DefaultStatisticsTarget = 0.0
	}
	if 10000 < plain.DefaultStatisticsTarget {
		return fmt.Errorf("field %s: must be <= %v", "default_statistics_target", 10000)
	}
	if 1 > plain.DefaultStatisticsTarget {
		return fmt.Errorf("field %s: must be >= %v", "default_statistics_target", 1)
	}
	if v, ok := raw["default_table_access_method"]; !ok || v == nil {
		plain.DefaultTableAccessMethod = "heap"
	}
	if v, ok := raw["default_text_search_config"]; !ok || v == nil {
		plain.DefaultTextSearchConfig = "pg_catalog.simple"
	}
	if v, ok := raw["default_toast_compression"]; !ok || v == nil {
		plain.DefaultToastCompression = "pglz"
	}
	if v, ok := raw["default_transaction_deferrable"]; !ok || v == nil {
		plain.DefaultTransactionDeferrable = false
	}
	if v, ok := raw["default_transaction_isolation"]; !ok || v == nil {
		plain.DefaultTransactionIsolation = "read committed"
	}
	if v, ok := raw["default_transaction_read_only"]; !ok || v == nil {
		plain.DefaultTransactionReadOnly = false
	}
	if v, ok := raw["dynamic_library_path"]; !ok || v == nil {
		plain.DynamicLibraryPath = "$libdir"
	}
	if v, ok := raw["dynamic_shared_memory_type"]; !ok || v == nil {
		plain.DynamicSharedMemoryType = types.ParseSize("posix")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.DynamicSharedMemoryType)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "DynamicSharedMemoryType", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["effective_cache_size"]; !ok || v == nil {
		plain.EffectiveCacheSize = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.EffectiveCacheSize)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "EffectiveCacheSize", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["effective_io_concurrency"]; !ok || v == nil {
		plain.EffectiveIoConcurrency = 0.0
	}
	if 1000 < plain.EffectiveIoConcurrency {
		return fmt.Errorf("field %s: must be <= %v", "effective_io_concurrency", 1000)
	}
	if v, ok := raw["enable_async_append"]; !ok || v == nil {
		plain.EnableAsyncAppend = false
	}
	if v, ok := raw["enable_bitmapscan"]; !ok || v == nil {
		plain.EnableBitmapscan = false
	}
	if v, ok := raw["enable_gathermerge"]; !ok || v == nil {
		plain.EnableGathermerge = false
	}
	if v, ok := raw["enable_group_by_reordering"]; !ok || v == nil {
		plain.EnableGroupByReordering = false
	}
	if v, ok := raw["enable_hashagg"]; !ok || v == nil {
		plain.EnableHashagg = false
	}
	if v, ok := raw["enable_hashjoin"]; !ok || v == nil {
		plain.EnableHashjoin = false
	}
	if v, ok := raw["enable_incremental_sort"]; !ok || v == nil {
		plain.EnableIncrementalSort = false
	}
	if v, ok := raw["enable_indexonlyscan"]; !ok || v == nil {
		plain.EnableIndexonlyscan = false
	}
	if v, ok := raw["enable_indexscan"]; !ok || v == nil {
		plain.EnableIndexscan = false
	}
	if v, ok := raw["enable_material"]; !ok || v == nil {
		plain.EnableMaterial = false
	}
	if v, ok := raw["enable_memoize"]; !ok || v == nil {
		plain.EnableMemoize = false
	}
	if v, ok := raw["enable_mergejoin"]; !ok || v == nil {
		plain.EnableMergejoin = false
	}
	if v, ok := raw["enable_nestloop"]; !ok || v == nil {
		plain.EnableNestloop = false
	}
	if v, ok := raw["enable_parallel_append"]; !ok || v == nil {
		plain.EnableParallelAppend = false
	}
	if v, ok := raw["enable_parallel_hash"]; !ok || v == nil {
		plain.EnableParallelHash = false
	}
	if v, ok := raw["enable_partition_pruning"]; !ok || v == nil {
		plain.EnablePartitionPruning = false
	}
	if v, ok := raw["enable_partitionwise_aggregate"]; !ok || v == nil {
		plain.EnablePartitionwiseAggregate = false
	}
	if v, ok := raw["enable_partitionwise_join"]; !ok || v == nil {
		plain.EnablePartitionwiseJoin = false
	}
	if v, ok := raw["enable_presorted_aggregate"]; !ok || v == nil {
		plain.EnablePresortedAggregate = false
	}
	if v, ok := raw["enable_seqscan"]; !ok || v == nil {
		plain.EnableSeqscan = false
	}
	if v, ok := raw["enable_sort"]; !ok || v == nil {
		plain.EnableSort = false
	}
	if v, ok := raw["enable_tidscan"]; !ok || v == nil {
		plain.EnableTidscan = false
	}
	if v, ok := raw["escape_string_warning"]; !ok || v == nil {
		plain.EscapeStringWarning = false
	}
	if v, ok := raw["event_source"]; !ok || v == nil {
		plain.EventSource = "PostgreSQL"
	}
	if v, ok := raw["event_triggers"]; !ok || v == nil {
		plain.EventTriggers = false
	}
	if v, ok := raw["exit_on_error"]; !ok || v == nil {
		plain.ExitOnError = false
	}
	if v, ok := raw["extra_float_digits"]; !ok || v == nil {
		plain.ExtraFloatDigits = 0.0
	}
	if 3 < plain.ExtraFloatDigits {
		return fmt.Errorf("field %s: must be <= %v", "extra_float_digits", 3)
	}
	if -15 > plain.ExtraFloatDigits {
		return fmt.Errorf("field %s: must be >= %v", "extra_float_digits", -15)
	}
	if v, ok := raw["from_collapse_limit"]; !ok || v == nil {
		plain.FromCollapseLimit = 0.0
	}
	if 2147483647 < plain.FromCollapseLimit {
		return fmt.Errorf("field %s: must be <= %v", "from_collapse_limit", 2147483647)
	}
	if 1 > plain.FromCollapseLimit {
		return fmt.Errorf("field %s: must be >= %v", "from_collapse_limit", 1)
	}
	if v, ok := raw["fsync"]; !ok || v == nil {
		plain.Fsync = false
	}
	if v, ok := raw["full_page_writes"]; !ok || v == nil {
		plain.FullPageWrites = false
	}
	if v, ok := raw["geqo"]; !ok || v == nil {
		plain.Geqo = false
	}
	if v, ok := raw["geqo_effort"]; !ok || v == nil {
		plain.GeqoEffort = 0.0
	}
	if 10 < plain.GeqoEffort {
		return fmt.Errorf("field %s: must be <= %v", "geqo_effort", 10)
	}
	if 1 > plain.GeqoEffort {
		return fmt.Errorf("field %s: must be >= %v", "geqo_effort", 1)
	}
	if v, ok := raw["geqo_generations"]; !ok || v == nil {
		plain.GeqoGenerations = 0.0
	}
	if 2147483647 < plain.GeqoGenerations {
		return fmt.Errorf("field %s: must be <= %v", "geqo_generations", 2147483647)
	}
	if v, ok := raw["geqo_pool_size"]; !ok || v == nil {
		plain.GeqoPoolSize = 0.0
	}
	if 2147483647 < plain.GeqoPoolSize {
		return fmt.Errorf("field %s: must be <= %v", "geqo_pool_size", 2147483647)
	}
	if v, ok := raw["geqo_seed"]; !ok || v == nil {
		plain.GeqoSeed = 0.0
	}
	if 1 < plain.GeqoSeed {
		return fmt.Errorf("field %s: must be <= %v", "geqo_seed", 1)
	}
	if v, ok := raw["geqo_selection_bias"]; !ok || v == nil {
		plain.GeqoSelectionBias = 0.0
	}
	if 2 < plain.GeqoSelectionBias {
		return fmt.Errorf("field %s: must be <= %v", "geqo_selection_bias", 2)
	}
	if 1.5 > plain.GeqoSelectionBias {
		return fmt.Errorf("field %s: must be >= %v", "geqo_selection_bias", 1.5)
	}
	if v, ok := raw["geqo_threshold"]; !ok || v == nil {
		plain.GeqoThreshold = 0.0
	}
	if 2147483647 < plain.GeqoThreshold {
		return fmt.Errorf("field %s: must be <= %v", "geqo_threshold", 2147483647)
	}
	if 2 > plain.GeqoThreshold {
		return fmt.Errorf("field %s: must be >= %v", "geqo_threshold", 2)
	}
	if v, ok := raw["gin_fuzzy_search_limit"]; !ok || v == nil {
		plain.GinFuzzySearchLimit = 0.0
	}
	if 2147483647 < plain.GinFuzzySearchLimit {
		return fmt.Errorf("field %s: must be <= %v", "gin_fuzzy_search_limit", 2147483647)
	}
	if v, ok := raw["gin_pending_list_limit"]; !ok || v == nil {
		plain.GinPendingListLimit = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.GinPendingListLimit)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "GinPendingListLimit", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["gss_accept_delegation"]; !ok || v == nil {
		plain.GssAcceptDelegation = false
	}
	if v, ok := raw["hash_mem_multiplier"]; !ok || v == nil {
		plain.HashMemMultiplier = 0.0
	}
	if 1000 < plain.HashMemMultiplier {
		return fmt.Errorf("field %s: must be <= %v", "hash_mem_multiplier", 1000)
	}
	if 1 > plain.HashMemMultiplier {
		return fmt.Errorf("field %s: must be >= %v", "hash_mem_multiplier", 1)
	}
	if v, ok := raw["hot_standby"]; !ok || v == nil {
		plain.HotStandby = false
	}
	if v, ok := raw["hot_standby_feedback"]; !ok || v == nil {
		plain.HotStandbyFeedback = false
	}
	if v, ok := raw["huge_page_size"]; !ok || v == nil {
		plain.HugePageSize = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.HugePageSize)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "HugePageSize", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["huge_pages"]; !ok || v == nil {
		plain.HugePages = "try"
	}
	if v, ok := raw["icu_validation_level"]; !ok || v == nil {
		plain.IcuValidationLevel = "warning"
	}
	if v, ok := raw["idle_in_transaction_session_timeout"]; !ok || v == nil {
		plain.IdleInTransactionSessionTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.IdleInTransactionSessionTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "IdleInTransactionSessionTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["idle_session_timeout"]; !ok || v == nil {
		plain.IdleSessionTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.IdleSessionTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "IdleSessionTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["io_combine_limit"]; !ok || v == nil {
		plain.IoCombineLimit = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.IoCombineLimit)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "IoCombineLimit", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["jit"]; !ok || v == nil {
		plain.Jit = false
	}
	if v, ok := raw["jit_above_cost"]; !ok || v == nil {
		plain.JitAboveCost = 0.0
	}
	if 1.79769e+308 < plain.JitAboveCost {
		return fmt.Errorf("field %s: must be <= %v", "jit_above_cost", 1.79769e+308)
	}
	if -1 > plain.JitAboveCost {
		return fmt.Errorf("field %s: must be >= %v", "jit_above_cost", -1)
	}
	if v, ok := raw["jit_inline_above_cost"]; !ok || v == nil {
		plain.JitInlineAboveCost = 0.0
	}
	if 1.79769e+308 < plain.JitInlineAboveCost {
		return fmt.Errorf("field %s: must be <= %v", "jit_inline_above_cost", 1.79769e+308)
	}
	if -1 > plain.JitInlineAboveCost {
		return fmt.Errorf("field %s: must be >= %v", "jit_inline_above_cost", -1)
	}
	if v, ok := raw["jit_optimize_above_cost"]; !ok || v == nil {
		plain.JitOptimizeAboveCost = 0.0
	}
	if 1.79769e+308 < plain.JitOptimizeAboveCost {
		return fmt.Errorf("field %s: must be <= %v", "jit_optimize_above_cost", 1.79769e+308)
	}
	if -1 > plain.JitOptimizeAboveCost {
		return fmt.Errorf("field %s: must be >= %v", "jit_optimize_above_cost", -1)
	}
	if v, ok := raw["jit_provider"]; !ok || v == nil {
		plain.JitProvider = "llvmjit"
	}
	if v, ok := raw["join_collapse_limit"]; !ok || v == nil {
		plain.JoinCollapseLimit = 0.0
	}
	if 2147483647 < plain.JoinCollapseLimit {
		return fmt.Errorf("field %s: must be <= %v", "join_collapse_limit", 2147483647)
	}
	if 1 > plain.JoinCollapseLimit {
		return fmt.Errorf("field %s: must be >= %v", "join_collapse_limit", 1)
	}
	if v, ok := raw["krb_caseins_users"]; !ok || v == nil {
		plain.KrbCaseinsUsers = false
	}
	if v, ok := raw["krb_server_keyfile"]; !ok || v == nil {
		plain.KrbServerKeyfile = "FILE:/usr/local/etc/postgresql/krb5.keytab"
	}
	if v, ok := raw["lc_monetary"]; !ok || v == nil {
		plain.LcMonetary = "C"
	}
	if v, ok := raw["lc_numeric"]; !ok || v == nil {
		plain.LcNumeric = "C"
	}
	if v, ok := raw["lc_time"]; !ok || v == nil {
		plain.LcTime = "C"
	}
	if v, ok := raw["listen_addresses"]; !ok || v == nil {
		plain.ListenAddresses = "localhost"
	}
	if v, ok := raw["lo_compat_privileges"]; !ok || v == nil {
		plain.LoCompatPrivileges = false
	}
	if v, ok := raw["lock_timeout"]; !ok || v == nil {
		plain.LockTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.LockTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "LockTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["log_autovacuum_min_duration"]; !ok || v == nil {
		plain.LogAutovacuumMinDuration = 0.0
	}
	if 2147483647 < plain.LogAutovacuumMinDuration {
		return fmt.Errorf("field %s: must be <= %v", "log_autovacuum_min_duration", 2147483647)
	}
	if -1 > plain.LogAutovacuumMinDuration {
		return fmt.Errorf("field %s: must be >= %v", "log_autovacuum_min_duration", -1)
	}
	if v, ok := raw["log_checkpoints"]; !ok || v == nil {
		plain.LogCheckpoints = false
	}
	if v, ok := raw["log_connections"]; !ok || v == nil {
		plain.LogConnections = false
	}
	if v, ok := raw["log_destination"]; !ok || v == nil {
		plain.LogDestination = "stderr"
	}
	if v, ok := raw["log_directory"]; !ok || v == nil {
		plain.LogDirectory = "log"
	}
	if v, ok := raw["log_disconnections"]; !ok || v == nil {
		plain.LogDisconnections = false
	}
	if v, ok := raw["log_duration"]; !ok || v == nil {
		plain.LogDuration = false
	}
	if v, ok := raw["log_error_verbosity"]; !ok || v == nil {
		plain.LogErrorVerbosity = "default"
	}
	if v, ok := raw["log_executor_stats"]; !ok || v == nil {
		plain.LogExecutorStats = false
	}
	if v, ok := raw["log_file_mode"]; !ok || v == nil {
		plain.LogFileMode = 0.0
	}
	if 511 < plain.LogFileMode {
		return fmt.Errorf("field %s: must be <= %v", "log_file_mode", 511)
	}
	if v, ok := raw["log_filename"]; !ok || v == nil {
		plain.LogFilename = "postgresql-%Y-%m-%d_%H%M%S.log"
	}
	if v, ok := raw["log_hostname"]; !ok || v == nil {
		plain.LogHostname = false
	}
	if v, ok := raw["log_line_prefix"]; !ok || v == nil {
		plain.LogLinePrefix = "%m [%p] "
	}
	if v, ok := raw["log_lock_waits"]; !ok || v == nil {
		plain.LogLockWaits = false
	}
	if v, ok := raw["log_min_duration_sample"]; !ok || v == nil {
		plain.LogMinDurationSample = 0.0
	}
	if 2147483647 < plain.LogMinDurationSample {
		return fmt.Errorf("field %s: must be <= %v", "log_min_duration_sample", 2147483647)
	}
	if -1 > plain.LogMinDurationSample {
		return fmt.Errorf("field %s: must be >= %v", "log_min_duration_sample", -1)
	}
	if v, ok := raw["log_min_duration_statement"]; !ok || v == nil {
		plain.LogMinDurationStatement = 0.0
	}
	if 2147483647 < plain.LogMinDurationStatement {
		return fmt.Errorf("field %s: must be <= %v", "log_min_duration_statement", 2147483647)
	}
	if -1 > plain.LogMinDurationStatement {
		return fmt.Errorf("field %s: must be >= %v", "log_min_duration_statement", -1)
	}
	if v, ok := raw["log_min_error_statement"]; !ok || v == nil {
		plain.LogMinErrorStatement = "error"
	}
	if v, ok := raw["log_min_messages"]; !ok || v == nil {
		plain.LogMinMessages = "warning"
	}
	if v, ok := raw["log_parameter_max_length"]; !ok || v == nil {
		plain.LogParameterMaxLength = 0.0
	}
	if 1073741823 < plain.LogParameterMaxLength {
		return fmt.Errorf("field %s: must be <= %v", "log_parameter_max_length", 1073741823)
	}
	if -1 > plain.LogParameterMaxLength {
		return fmt.Errorf("field %s: must be >= %v", "log_parameter_max_length", -1)
	}
	if v, ok := raw["log_parameter_max_length_on_error"]; !ok || v == nil {
		plain.LogParameterMaxLengthOnError = 0.0
	}
	if 1073741823 < plain.LogParameterMaxLengthOnError {
		return fmt.Errorf("field %s: must be <= %v", "log_parameter_max_length_on_error", 1073741823)
	}
	if -1 > plain.LogParameterMaxLengthOnError {
		return fmt.Errorf("field %s: must be >= %v", "log_parameter_max_length_on_error", -1)
	}
	if v, ok := raw["log_parser_stats"]; !ok || v == nil {
		plain.LogParserStats = false
	}
	if v, ok := raw["log_planner_stats"]; !ok || v == nil {
		plain.LogPlannerStats = false
	}
	if v, ok := raw["log_recovery_conflict_waits"]; !ok || v == nil {
		plain.LogRecoveryConflictWaits = false
	}
	if v, ok := raw["log_replication_commands"]; !ok || v == nil {
		plain.LogReplicationCommands = false
	}
	if v, ok := raw["log_rotation_age"]; !ok || v == nil {
		plain.LogRotationAge = 0.0
	}
	if 35791394 < plain.LogRotationAge {
		return fmt.Errorf("field %s: must be <= %v", "log_rotation_age", 35791394)
	}
	if v, ok := raw["log_rotation_size"]; !ok || v == nil {
		plain.LogRotationSize = 0.0
	}
	if 2097151 < plain.LogRotationSize {
		return fmt.Errorf("field %s: must be <= %v", "log_rotation_size", 2097151)
	}
	if v, ok := raw["log_startup_progress_interval"]; !ok || v == nil {
		plain.LogStartupProgressInterval = 0.0
	}
	if 2147483647 < plain.LogStartupProgressInterval {
		return fmt.Errorf("field %s: must be <= %v", "log_startup_progress_interval", 2147483647)
	}
	if v, ok := raw["log_statement"]; !ok || v == nil {
		plain.LogStatement = "none"
	}
	if v, ok := raw["log_statement_sample_rate"]; !ok || v == nil {
		plain.LogStatementSampleRate = 0.0
	}
	if 1 < plain.LogStatementSampleRate {
		return fmt.Errorf("field %s: must be <= %v", "log_statement_sample_rate", 1)
	}
	if v, ok := raw["log_statement_stats"]; !ok || v == nil {
		plain.LogStatementStats = false
	}
	if v, ok := raw["log_temp_files"]; !ok || v == nil {
		plain.LogTempFiles = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.LogTempFiles)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "LogTempFiles", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["log_timezone"]; !ok || v == nil {
		plain.LogTimezone = "GMT"
	}
	if v, ok := raw["log_transaction_sample_rate"]; !ok || v == nil {
		plain.LogTransactionSampleRate = 0.0
	}
	if 1 < plain.LogTransactionSampleRate {
		return fmt.Errorf("field %s: must be <= %v", "log_transaction_sample_rate", 1)
	}
	if v, ok := raw["log_truncate_on_rotation"]; !ok || v == nil {
		plain.LogTruncateOnRotation = false
	}
	if v, ok := raw["logging_collector"]; !ok || v == nil {
		plain.LoggingCollector = false
	}
	if v, ok := raw["logical_decoding_work_mem"]; !ok || v == nil {
		plain.LogicalDecodingWorkMem = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.LogicalDecodingWorkMem)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "LogicalDecodingWorkMem", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["maintenance_io_concurrency"]; !ok || v == nil {
		plain.MaintenanceIoConcurrency = 0.0
	}
	if 1000 < plain.MaintenanceIoConcurrency {
		return fmt.Errorf("field %s: must be <= %v", "maintenance_io_concurrency", 1000)
	}
	if v, ok := raw["maintenance_work_mem"]; !ok || v == nil {
		plain.MaintenanceWorkMem = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MaintenanceWorkMem)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MaintenanceWorkMem", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["max_connections"]; !ok || v == nil {
		plain.MaxConnections = 0.0
	}
	if 262143 < plain.MaxConnections {
		return fmt.Errorf("field %s: must be <= %v", "max_connections", 262143)
	}
	if 1 > plain.MaxConnections {
		return fmt.Errorf("field %s: must be >= %v", "max_connections", 1)
	}
	if v, ok := raw["max_files_per_process"]; !ok || v == nil {
		plain.MaxFilesPerProcess = 0.0
	}
	if 2147483647 < plain.MaxFilesPerProcess {
		return fmt.Errorf("field %s: must be <= %v", "max_files_per_process", 2147483647)
	}
	if 64 > plain.MaxFilesPerProcess {
		return fmt.Errorf("field %s: must be >= %v", "max_files_per_process", 64)
	}
	if v, ok := raw["max_locks_per_transaction"]; !ok || v == nil {
		plain.MaxLocksPerTransaction = 0.0
	}
	if 2147483647 < plain.MaxLocksPerTransaction {
		return fmt.Errorf("field %s: must be <= %v", "max_locks_per_transaction", 2147483647)
	}
	if 10 > plain.MaxLocksPerTransaction {
		return fmt.Errorf("field %s: must be >= %v", "max_locks_per_transaction", 10)
	}
	if v, ok := raw["max_logical_replication_workers"]; !ok || v == nil {
		plain.MaxLogicalReplicationWorkers = 0.0
	}
	if 262143 < plain.MaxLogicalReplicationWorkers {
		return fmt.Errorf("field %s: must be <= %v", "max_logical_replication_workers", 262143)
	}
	if v, ok := raw["max_notify_queue_pages"]; !ok || v == nil {
		plain.MaxNotifyQueuePages = 0.0
	}
	if 2147483647 < plain.MaxNotifyQueuePages {
		return fmt.Errorf("field %s: must be <= %v", "max_notify_queue_pages", 2147483647)
	}
	if 64 > plain.MaxNotifyQueuePages {
		return fmt.Errorf("field %s: must be >= %v", "max_notify_queue_pages", 64)
	}
	if v, ok := raw["max_parallel_apply_workers_per_subscription"]; !ok || v == nil {
		plain.MaxParallelApplyWorkersPerSubscription = 0.0
	}
	if 1024 < plain.MaxParallelApplyWorkersPerSubscription {
		return fmt.Errorf("field %s: must be <= %v", "max_parallel_apply_workers_per_subscription", 1024)
	}
	if v, ok := raw["max_parallel_maintenance_workers"]; !ok || v == nil {
		plain.MaxParallelMaintenanceWorkers = 0.0
	}
	if 1024 < plain.MaxParallelMaintenanceWorkers {
		return fmt.Errorf("field %s: must be <= %v", "max_parallel_maintenance_workers", 1024)
	}
	if v, ok := raw["max_parallel_workers"]; !ok || v == nil {
		plain.MaxParallelWorkers = 0.0
	}
	if 1024 < plain.MaxParallelWorkers {
		return fmt.Errorf("field %s: must be <= %v", "max_parallel_workers", 1024)
	}
	if v, ok := raw["max_parallel_workers_per_gather"]; !ok || v == nil {
		plain.MaxParallelWorkersPerGather = 0.0
	}
	if 1024 < plain.MaxParallelWorkersPerGather {
		return fmt.Errorf("field %s: must be <= %v", "max_parallel_workers_per_gather", 1024)
	}
	if v, ok := raw["max_pred_locks_per_page"]; !ok || v == nil {
		plain.MaxPredLocksPerPage = 0.0
	}
	if 2147483647 < plain.MaxPredLocksPerPage {
		return fmt.Errorf("field %s: must be <= %v", "max_pred_locks_per_page", 2147483647)
	}
	if v, ok := raw["max_pred_locks_per_relation"]; !ok || v == nil {
		plain.MaxPredLocksPerRelation = 0.0
	}
	if 2147483647 < plain.MaxPredLocksPerRelation {
		return fmt.Errorf("field %s: must be <= %v", "max_pred_locks_per_relation", 2147483647)
	}
	if -2147483648 > plain.MaxPredLocksPerRelation {
		return fmt.Errorf("field %s: must be >= %v", "max_pred_locks_per_relation", -2147483648)
	}
	if v, ok := raw["max_pred_locks_per_transaction"]; !ok || v == nil {
		plain.MaxPredLocksPerTransaction = 0.0
	}
	if 2147483647 < plain.MaxPredLocksPerTransaction {
		return fmt.Errorf("field %s: must be <= %v", "max_pred_locks_per_transaction", 2147483647)
	}
	if 10 > plain.MaxPredLocksPerTransaction {
		return fmt.Errorf("field %s: must be >= %v", "max_pred_locks_per_transaction", 10)
	}
	if v, ok := raw["max_prepared_transactions"]; !ok || v == nil {
		plain.MaxPreparedTransactions = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MaxPreparedTransactions)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MaxPreparedTransactions", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["max_replication_slots"]; !ok || v == nil {
		plain.MaxReplicationSlots = 0.0
	}
	if 262143 < plain.MaxReplicationSlots {
		return fmt.Errorf("field %s: must be <= %v", "max_replication_slots", 262143)
	}
	if v, ok := raw["max_slot_wal_keep_size"]; !ok || v == nil {
		plain.MaxSlotWalKeepSize = 0.0
	}
	if 2147483647 < plain.MaxSlotWalKeepSize {
		return fmt.Errorf("field %s: must be <= %v", "max_slot_wal_keep_size", 2147483647)
	}
	if -1 > plain.MaxSlotWalKeepSize {
		return fmt.Errorf("field %s: must be >= %v", "max_slot_wal_keep_size", -1)
	}
	if v, ok := raw["max_stack_depth"]; !ok || v == nil {
		plain.MaxStackDepth = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MaxStackDepth)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MaxStackDepth", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["max_standby_archive_delay"]; !ok || v == nil {
		plain.MaxStandbyArchiveDelay = 0.0
	}
	if 2147483647 < plain.MaxStandbyArchiveDelay {
		return fmt.Errorf("field %s: must be <= %v", "max_standby_archive_delay", 2147483647)
	}
	if -1 > plain.MaxStandbyArchiveDelay {
		return fmt.Errorf("field %s: must be >= %v", "max_standby_archive_delay", -1)
	}
	if v, ok := raw["max_standby_streaming_delay"]; !ok || v == nil {
		plain.MaxStandbyStreamingDelay = 0.0
	}
	if 2147483647 < plain.MaxStandbyStreamingDelay {
		return fmt.Errorf("field %s: must be <= %v", "max_standby_streaming_delay", 2147483647)
	}
	if -1 > plain.MaxStandbyStreamingDelay {
		return fmt.Errorf("field %s: must be >= %v", "max_standby_streaming_delay", -1)
	}
	if v, ok := raw["max_sync_workers_per_subscription"]; !ok || v == nil {
		plain.MaxSyncWorkersPerSubscription = 0.0
	}
	if 262143 < plain.MaxSyncWorkersPerSubscription {
		return fmt.Errorf("field %s: must be <= %v", "max_sync_workers_per_subscription", 262143)
	}
	if v, ok := raw["max_wal_senders"]; !ok || v == nil {
		plain.MaxWalSenders = 0.0
	}
	if 262143 < plain.MaxWalSenders {
		return fmt.Errorf("field %s: must be <= %v", "max_wal_senders", 262143)
	}
	if v, ok := raw["max_wal_size"]; !ok || v == nil {
		plain.MaxWalSize = 0.0
	}
	if 2147483647 < plain.MaxWalSize {
		return fmt.Errorf("field %s: must be <= %v", "max_wal_size", 2147483647)
	}
	if 2 > plain.MaxWalSize {
		return fmt.Errorf("field %s: must be >= %v", "max_wal_size", 2)
	}
	if v, ok := raw["max_worker_processes"]; !ok || v == nil {
		plain.MaxWorkerProcesses = 0.0
	}
	if 262143 < plain.MaxWorkerProcesses {
		return fmt.Errorf("field %s: must be <= %v", "max_worker_processes", 262143)
	}
	if v, ok := raw["min_dynamic_shared_memory"]; !ok || v == nil {
		plain.MinDynamicSharedMemory = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MinDynamicSharedMemory)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MinDynamicSharedMemory", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["min_parallel_index_scan_size"]; !ok || v == nil {
		plain.MinParallelIndexScanSize = 0.0
	}
	if 715827882 < plain.MinParallelIndexScanSize {
		return fmt.Errorf("field %s: must be <= %v", "min_parallel_index_scan_size", 715827882)
	}
	if v, ok := raw["min_parallel_table_scan_size"]; !ok || v == nil {
		plain.MinParallelTableScanSize = 0.0
	}
	if 715827882 < plain.MinParallelTableScanSize {
		return fmt.Errorf("field %s: must be <= %v", "min_parallel_table_scan_size", 715827882)
	}
	if v, ok := raw["min_wal_size"]; !ok || v == nil {
		plain.MinWalSize = 0.0
	}
	if 2147483647 < plain.MinWalSize {
		return fmt.Errorf("field %s: must be <= %v", "min_wal_size", 2147483647)
	}
	if 2 > plain.MinWalSize {
		return fmt.Errorf("field %s: must be >= %v", "min_wal_size", 2)
	}
	if v, ok := raw["multixact_member_buffers"]; !ok || v == nil {
		plain.MultixactMemberBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MultixactMemberBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MultixactMemberBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["multixact_offset_buffers"]; !ok || v == nil {
		plain.MultixactOffsetBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.MultixactOffsetBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "MultixactOffsetBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["notify_buffers"]; !ok || v == nil {
		plain.NotifyBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.NotifyBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "NotifyBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["parallel_leader_participation"]; !ok || v == nil {
		plain.ParallelLeaderParticipation = false
	}
	if v, ok := raw["parallel_setup_cost"]; !ok || v == nil {
		plain.ParallelSetupCost = 0.0
	}
	if 1.79769e+308 < plain.ParallelSetupCost {
		return fmt.Errorf("field %s: must be <= %v", "parallel_setup_cost", 1.79769e+308)
	}
	if v, ok := raw["parallel_tuple_cost"]; !ok || v == nil {
		plain.ParallelTupleCost = 0.0
	}
	if 1.79769e+308 < plain.ParallelTupleCost {
		return fmt.Errorf("field %s: must be <= %v", "parallel_tuple_cost", 1.79769e+308)
	}
	if v, ok := raw["password_encryption"]; !ok || v == nil {
		plain.PasswordEncryption = "scram-sha-256"
	}
	if v, ok := raw["plan_cache_mode"]; !ok || v == nil {
		plain.PlanCacheMode = "auto"
	}
	if v, ok := raw["port"]; !ok || v == nil {
		plain.Port = 0.0
	}
	if 65535 < plain.Port {
		return fmt.Errorf("field %s: must be <= %v", "port", 65535)
	}
	if 1 > plain.Port {
		return fmt.Errorf("field %s: must be >= %v", "port", 1)
	}
	if v, ok := raw["quote_all_identifiers"]; !ok || v == nil {
		plain.QuoteAllIdentifiers = false
	}
	if v, ok := raw["random_page_cost"]; !ok || v == nil {
		plain.RandomPageCost = 0.0
	}
	if 1.79769e+308 < plain.RandomPageCost {
		return fmt.Errorf("field %s: must be <= %v", "random_page_cost", 1.79769e+308)
	}
	if v, ok := raw["recovery_init_sync_method"]; !ok || v == nil {
		plain.RecoveryInitSyncMethod = "fsync"
	}
	if v, ok := raw["recovery_min_apply_delay"]; !ok || v == nil {
		plain.RecoveryMinApplyDelay = 0.0
	}
	if 2147483647 < plain.RecoveryMinApplyDelay {
		return fmt.Errorf("field %s: must be <= %v", "recovery_min_apply_delay", 2147483647)
	}
	if v, ok := raw["recovery_prefetch"]; !ok || v == nil {
		plain.RecoveryPrefetch = types.ParseSize("try")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.RecoveryPrefetch)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "RecoveryPrefetch", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["recovery_target_action"]; !ok || v == nil {
		plain.RecoveryTargetAction = "pause"
	}
	if v, ok := raw["recovery_target_inclusive"]; !ok || v == nil {
		plain.RecoveryTargetInclusive = false
	}
	if v, ok := raw["recovery_target_timeline"]; !ok || v == nil {
		plain.RecoveryTargetTimeline = "latest"
	}
	if v, ok := raw["recursive_worktable_factor"]; !ok || v == nil {
		plain.RecursiveWorktableFactor = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.RecursiveWorktableFactor)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "RecursiveWorktableFactor", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["reserved_connections"]; !ok || v == nil {
		plain.ReservedConnections = 0.0
	}
	if 262143 < plain.ReservedConnections {
		return fmt.Errorf("field %s: must be <= %v", "reserved_connections", 262143)
	}
	if v, ok := raw["restart_after_crash"]; !ok || v == nil {
		plain.RestartAfterCrash = false
	}
	if v, ok := raw["row_security"]; !ok || v == nil {
		plain.RowSecurity = false
	}
	if v, ok := raw["scram_iterations"]; !ok || v == nil {
		plain.ScramIterations = 0.0
	}
	if 2147483647 < plain.ScramIterations {
		return fmt.Errorf("field %s: must be <= %v", "scram_iterations", 2147483647)
	}
	if 1 > plain.ScramIterations {
		return fmt.Errorf("field %s: must be >= %v", "scram_iterations", 1)
	}
	if v, ok := raw["search_path"]; !ok || v == nil {
		plain.SearchPath = "\"$user\", public"
	}
	if v, ok := raw["seq_page_cost"]; !ok || v == nil {
		plain.SeqPageCost = 0.0
	}
	if 1.79769e+308 < plain.SeqPageCost {
		return fmt.Errorf("field %s: must be <= %v", "seq_page_cost", 1.79769e+308)
	}
	if v, ok := raw["serializable_buffers"]; !ok || v == nil {
		plain.SerializableBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.SerializableBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "SerializableBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["session_replication_role"]; !ok || v == nil {
		plain.SessionReplicationRole = "origin"
	}
	if v, ok := raw["shared_buffers"]; !ok || v == nil {
		plain.SharedBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.SharedBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "SharedBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["shared_memory_type"]; !ok || v == nil {
		plain.SharedMemoryType = types.ParseSize("mmap")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.SharedMemoryType)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "SharedMemoryType", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["ssl"]; !ok || v == nil {
		plain.Ssl = false
	}
	if v, ok := raw["ssl_cert_file"]; !ok || v == nil {
		plain.SslCertFile = "server.crt"
	}
	if v, ok := raw["ssl_ciphers"]; !ok || v == nil {
		plain.SslCiphers = "HIGH:MEDIUM:+3DES:!aNULL"
	}
	if v, ok := raw["ssl_ecdh_curve"]; !ok || v == nil {
		plain.SslEcdhCurve = "prime256v1"
	}
	if v, ok := raw["ssl_key_file"]; !ok || v == nil {
		plain.SslKeyFile = "server.key"
	}
	if v, ok := raw["ssl_min_protocol_version"]; !ok || v == nil {
		plain.SslMinProtocolVersion = "TLSv1.2"
	}
	if v, ok := raw["ssl_passphrase_command_supports_reload"]; !ok || v == nil {
		plain.SslPassphraseCommandSupportsReload = false
	}
	if v, ok := raw["ssl_prefer_server_ciphers"]; !ok || v == nil {
		plain.SslPreferServerCiphers = false
	}
	if v, ok := raw["standard_conforming_strings"]; !ok || v == nil {
		plain.StandardConformingStrings = false
	}
	if v, ok := raw["statement_timeout"]; !ok || v == nil {
		plain.StatementTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.StatementTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "StatementTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["stats_fetch_consistency"]; !ok || v == nil {
		plain.StatsFetchConsistency = "cache"
	}
	if v, ok := raw["subtransaction_buffers"]; !ok || v == nil {
		plain.SubtransactionBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.SubtransactionBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "SubtransactionBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["summarize_wal"]; !ok || v == nil {
		plain.SummarizeWal = false
	}
	if v, ok := raw["superuser_reserved_connections"]; !ok || v == nil {
		plain.SuperuserReservedConnections = 0.0
	}
	if 262143 < plain.SuperuserReservedConnections {
		return fmt.Errorf("field %s: must be <= %v", "superuser_reserved_connections", 262143)
	}
	if v, ok := raw["sync_replication_slots"]; !ok || v == nil {
		plain.SyncReplicationSlots = false
	}
	if v, ok := raw["synchronize_seqscans"]; !ok || v == nil {
		plain.SynchronizeSeqscans = false
	}
	if v, ok := raw["synchronous_commit"]; !ok || v == nil {
		plain.SynchronousCommit = "on"
	}
	if v, ok := raw["syslog_facility"]; !ok || v == nil {
		plain.SyslogFacility = "local0"
	}
	if v, ok := raw["syslog_ident"]; !ok || v == nil {
		plain.SyslogIdent = "postgres"
	}
	if v, ok := raw["syslog_sequence_numbers"]; !ok || v == nil {
		plain.SyslogSequenceNumbers = false
	}
	if v, ok := raw["syslog_split_messages"]; !ok || v == nil {
		plain.SyslogSplitMessages = false
	}
	if v, ok := raw["tcp_keepalives_count"]; !ok || v == nil {
		plain.TcpKeepalivesCount = 0.0
	}
	if 2147483647 < plain.TcpKeepalivesCount {
		return fmt.Errorf("field %s: must be <= %v", "tcp_keepalives_count", 2147483647)
	}
	if v, ok := raw["tcp_keepalives_idle"]; !ok || v == nil {
		plain.TcpKeepalivesIdle = 0.0
	}
	if 2147483647 < plain.TcpKeepalivesIdle {
		return fmt.Errorf("field %s: must be <= %v", "tcp_keepalives_idle", 2147483647)
	}
	if v, ok := raw["tcp_keepalives_interval"]; !ok || v == nil {
		plain.TcpKeepalivesInterval = 0.0
	}
	if 2147483647 < plain.TcpKeepalivesInterval {
		return fmt.Errorf("field %s: must be <= %v", "tcp_keepalives_interval", 2147483647)
	}
	if v, ok := raw["tcp_user_timeout"]; !ok || v == nil {
		plain.TcpUserTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.TcpUserTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "TcpUserTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["temp_buffers"]; !ok || v == nil {
		plain.TempBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.TempBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "TempBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["temp_file_limit"]; !ok || v == nil {
		plain.TempFileLimit = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.TempFileLimit)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "TempFileLimit", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["track_activities"]; !ok || v == nil {
		plain.TrackActivities = false
	}
	if v, ok := raw["track_activity_query_size"]; !ok || v == nil {
		plain.TrackActivityQuerySize = 0.0
	}
	if 1048576 < plain.TrackActivityQuerySize {
		return fmt.Errorf("field %s: must be <= %v", "track_activity_query_size", 1048576)
	}
	if 100 > plain.TrackActivityQuerySize {
		return fmt.Errorf("field %s: must be >= %v", "track_activity_query_size", 100)
	}
	if v, ok := raw["track_commit_timestamp"]; !ok || v == nil {
		plain.TrackCommitTimestamp = false
	}
	if v, ok := raw["track_counts"]; !ok || v == nil {
		plain.TrackCounts = false
	}
	if v, ok := raw["track_functions"]; !ok || v == nil {
		plain.TrackFunctions = "none"
	}
	if v, ok := raw["track_io_timing"]; !ok || v == nil {
		plain.TrackIoTiming = false
	}
	if v, ok := raw["track_wal_io_timing"]; !ok || v == nil {
		plain.TrackWalIoTiming = false
	}
	if v, ok := raw["transaction_buffers"]; !ok || v == nil {
		plain.TransactionBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.TransactionBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "TransactionBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["transaction_timeout"]; !ok || v == nil {
		plain.TransactionTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.TransactionTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "TransactionTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["transform_null_equals"]; !ok || v == nil {
		plain.TransformNullEquals = false
	}
	if v, ok := raw["unix_socket_directories"]; !ok || v == nil {
		plain.UnixSocketDirectories = "/tmp"
	}
	if v, ok := raw["unix_socket_permissions"]; !ok || v == nil {
		plain.UnixSocketPermissions = 0.0
	}
	if 511 < plain.UnixSocketPermissions {
		return fmt.Errorf("field %s: must be <= %v", "unix_socket_permissions", 511)
	}
	if v, ok := raw["update_process_title"]; !ok || v == nil {
		plain.UpdateProcessTitle = false
	}
	if v, ok := raw["vacuum_buffer_usage_limit"]; !ok || v == nil {
		plain.VacuumBufferUsageLimit = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.VacuumBufferUsageLimit)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "VacuumBufferUsageLimit", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["vacuum_cost_delay"]; !ok || v == nil {
		plain.VacuumCostDelay = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.VacuumCostDelay)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "VacuumCostDelay", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["vacuum_cost_limit"]; !ok || v == nil {
		plain.VacuumCostLimit = 0.0
	}
	if 10000 < plain.VacuumCostLimit {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_cost_limit", 10000)
	}
	if 1 > plain.VacuumCostLimit {
		return fmt.Errorf("field %s: must be >= %v", "vacuum_cost_limit", 1)
	}
	if v, ok := raw["vacuum_cost_page_dirty"]; !ok || v == nil {
		plain.VacuumCostPageDirty = 0.0
	}
	if 10000 < plain.VacuumCostPageDirty {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_cost_page_dirty", 10000)
	}
	if v, ok := raw["vacuum_cost_page_hit"]; !ok || v == nil {
		plain.VacuumCostPageHit = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.VacuumCostPageHit)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "VacuumCostPageHit", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["vacuum_cost_page_miss"]; !ok || v == nil {
		plain.VacuumCostPageMiss = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.VacuumCostPageMiss)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "VacuumCostPageMiss", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["vacuum_failsafe_age"]; !ok || v == nil {
		plain.VacuumFailsafeAge = 0.0
	}
	if 2100000000 < plain.VacuumFailsafeAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_failsafe_age", 2100000000)
	}
	if v, ok := raw["vacuum_freeze_min_age"]; !ok || v == nil {
		plain.VacuumFreezeMinAge = 0.0
	}
	if 1000000000 < plain.VacuumFreezeMinAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_freeze_min_age", 1000000000)
	}
	if v, ok := raw["vacuum_freeze_table_age"]; !ok || v == nil {
		plain.VacuumFreezeTableAge = 0.0
	}
	if 2000000000 < plain.VacuumFreezeTableAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_freeze_table_age", 2000000000)
	}
	if v, ok := raw["vacuum_multixact_failsafe_age"]; !ok || v == nil {
		plain.VacuumMultixactFailsafeAge = 0.0
	}
	if 2100000000 < plain.VacuumMultixactFailsafeAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_multixact_failsafe_age", 2100000000)
	}
	if v, ok := raw["vacuum_multixact_freeze_min_age"]; !ok || v == nil {
		plain.VacuumMultixactFreezeMinAge = 0.0
	}
	if 1000000000 < plain.VacuumMultixactFreezeMinAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_multixact_freeze_min_age", 1000000000)
	}
	if v, ok := raw["vacuum_multixact_freeze_table_age"]; !ok || v == nil {
		plain.VacuumMultixactFreezeTableAge = 0.0
	}
	if 2000000000 < plain.VacuumMultixactFreezeTableAge {
		return fmt.Errorf("field %s: must be <= %v", "vacuum_multixact_freeze_table_age", 2000000000)
	}
	if v, ok := raw["wal_buffers"]; !ok || v == nil {
		plain.WalBuffers = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.WalBuffers)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalBuffers", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["wal_compression"]; !ok || v == nil {
		plain.WalCompression = "off"
	}
	if v, ok := raw["wal_decode_buffer_size"]; !ok || v == nil {
		plain.WalDecodeBufferSize = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.WalDecodeBufferSize)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalDecodeBufferSize", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["wal_init_zero"]; !ok || v == nil {
		plain.WalInitZero = false
	}
	if v, ok := raw["wal_keep_size"]; !ok || v == nil {
		plain.WalKeepSize = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.WalKeepSize)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalKeepSize", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["wal_level"]; !ok || v == nil {
		plain.WalLevel = "replica"
	}
	if v, ok := raw["wal_log_hints"]; !ok || v == nil {
		plain.WalLogHints = false
	}
	if v, ok := raw["wal_receiver_create_temp_slot"]; !ok || v == nil {
		plain.WalReceiverCreateTempSlot = false
	}
	if v, ok := raw["wal_receiver_status_interval"]; !ok || v == nil {
		plain.WalReceiverStatusInterval = 0.0
	}
	if 2147483 < plain.WalReceiverStatusInterval {
		return fmt.Errorf("field %s: must be <= %v", "wal_receiver_status_interval", 2147483)
	}
	if v, ok := raw["wal_receiver_timeout"]; !ok || v == nil {
		plain.WalReceiverTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.WalReceiverTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalReceiverTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["wal_recycle"]; !ok || v == nil {
		plain.WalRecycle = false
	}
	if v, ok := raw["wal_retrieve_retry_interval"]; !ok || v == nil {
		plain.WalRetrieveRetryInterval = 0.0
	}
	if 2147483647 < plain.WalRetrieveRetryInterval {
		return fmt.Errorf("field %s: must be <= %v", "wal_retrieve_retry_interval", 2147483647)
	}
	if 1 > plain.WalRetrieveRetryInterval {
		return fmt.Errorf("field %s: must be >= %v", "wal_retrieve_retry_interval", 1)
	}
	if v, ok := raw["wal_sender_timeout"]; !ok || v == nil {
		plain.WalSenderTimeout = types.ParseDuration("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+(us|ms|s|min|h|d)?$`, string(plain.WalSenderTimeout)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalSenderTimeout", `^[0-9]+(us|ms|s|min|h|d)?$`)
	}
	if v, ok := raw["wal_skip_threshold"]; !ok || v == nil {
		plain.WalSkipThreshold = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.WalSkipThreshold)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WalSkipThreshold", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["wal_summary_keep_time"]; !ok || v == nil {
		plain.WalSummaryKeepTime = 0.0
	}
	if 35791394 < plain.WalSummaryKeepTime {
		return fmt.Errorf("field %s: must be <= %v", "wal_summary_keep_time", 35791394)
	}
	if v, ok := raw["wal_sync_method"]; !ok || v == nil {
		plain.WalSyncMethod = "open_datasync"
	}
	if v, ok := raw["wal_writer_delay"]; !ok || v == nil {
		plain.WalWriterDelay = 0.0
	}
	if 10000 < plain.WalWriterDelay {
		return fmt.Errorf("field %s: must be <= %v", "wal_writer_delay", 10000)
	}
	if 1 > plain.WalWriterDelay {
		return fmt.Errorf("field %s: must be >= %v", "wal_writer_delay", 1)
	}
	if v, ok := raw["wal_writer_flush_after"]; !ok || v == nil {
		plain.WalWriterFlushAfter = 0.0
	}
	if 2147483647 < plain.WalWriterFlushAfter {
		return fmt.Errorf("field %s: must be <= %v", "wal_writer_flush_after", 2147483647)
	}
	if v, ok := raw["work_mem"]; !ok || v == nil {
		plain.WorkMem = types.ParseSize("0")
	}
	if matched, _ := regexp.MatchString(`^[0-9]+[kMGT]?B$`, string(plain.WorkMem)); !matched {
		return fmt.Errorf("field %s pattern match: must match %s", "WorkMem", `^[0-9]+[kMGT]?B$`)
	}
	if v, ok := raw["xmlbinary"]; !ok || v == nil {
		plain.Xmlbinary = "base64"
	}
	if v, ok := raw["xmloption"]; !ok || v == nil {
		plain.Xmloption = "content"
	}
	*j = PostgresConf(plain)
	return nil
}

// PostgREST API server configuration
type PostgrestConf struct {
	// Database role with admin privileges
	AdminRole string `json:"admin_role,omitempty" yaml:"admin_role,omitempty" mapstructure:"admin_role,omitempty"`

	// Database role for anonymous access
	AnonymousRole string `json:"anonymous_role,omitempty" yaml:"anonymous_role,omitempty" mapstructure:"anonymous_role,omitempty"`

	// Database connection pool size
	DbPool int `json:"db_pool,omitempty" yaml:"db_pool,omitempty" mapstructure:"db_pool,omitempty"`

	// Database connection pool timeout in seconds
	DbPoolTimeout int `json:"db_pool_timeout,omitempty" yaml:"db_pool_timeout,omitempty" mapstructure:"db_pool_timeout,omitempty"`

	// Database schemas to expose via API
	DbSchemas string `json:"db_schemas,omitempty" yaml:"db_schemas,omitempty" mapstructure:"db_schemas,omitempty"`

	// Database connection URI
	DbUri *string `json:"db_uri,omitempty" yaml:"db_uri,omitempty" mapstructure:"db_uri,omitempty"`

	// JWT audience claim
	JwtAud string `json:"jwt_aud,omitempty" yaml:"jwt_aud,omitempty" mapstructure:"jwt_aud,omitempty"`

	// JWT secret for authentication
	JwtSecret *string `json:"jwt_secret,omitempty" yaml:"jwt_secret,omitempty" mapstructure:"jwt_secret,omitempty"`

	// Whether JWT secret is base64 encoded
	JwtSecretIsBase64 bool `json:"jwt_secret_is_base64,omitempty" yaml:"jwt_secret_is_base64,omitempty" mapstructure:"jwt_secret_is_base64,omitempty"`

	// Logging level
	LogLevel PostgrestConfLogLevel `json:"log_level,omitempty" yaml:"log_level,omitempty" mapstructure:"log_level,omitempty"`

	// Maximum rows returned in a single response
	MaxRows *int `json:"max_rows,omitempty" yaml:"max_rows,omitempty" mapstructure:"max_rows,omitempty"`

	// Pre-request function to call
	PreRequest string `json:"pre_request,omitempty" yaml:"pre_request,omitempty" mapstructure:"pre_request,omitempty"`

	// JWT claim key for role
	RoleClaimKey string `json:"role_claim_key,omitempty" yaml:"role_claim_key,omitempty" mapstructure:"role_claim_key,omitempty"`

	// Server host address
	ServerHost string `json:"server_host,omitempty" yaml:"server_host,omitempty" mapstructure:"server_host,omitempty"`

	// Server port
	ServerPort int `json:"server_port,omitempty" yaml:"server_port,omitempty" mapstructure:"server_port,omitempty"`

	// Path to SSL certificate file
	ServerSslCert string `json:"server_ssl_cert,omitempty" yaml:"server_ssl_cert,omitempty" mapstructure:"server_ssl_cert,omitempty"`

	// Path to SSL private key file
	ServerSslKey string `json:"server_ssl_key,omitempty" yaml:"server_ssl_key,omitempty" mapstructure:"server_ssl_key,omitempty"`
}

type PostgrestConfLogLevel string

const PostgrestConfLogLevelCrit PostgrestConfLogLevel = "crit"
const PostgrestConfLogLevelDebug PostgrestConfLogLevel = "debug"
const PostgrestConfLogLevelError PostgrestConfLogLevel = "error"
const PostgrestConfLogLevelInfo PostgrestConfLogLevel = "info"
const PostgrestConfLogLevelWarn PostgrestConfLogLevel = "warn"

var enumValues_PostgrestConfLogLevel = []interface{}{
	"crit",
	"error",
	"warn",
	"info",
	"debug",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgrestConfLogLevel) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_PostgrestConfLogLevel {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_PostgrestConfLogLevel, v)
	}
	*j = PostgrestConfLogLevel(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *PostgrestConf) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain PostgrestConf
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["admin_role"]; !ok || v == nil {
		plain.AdminRole = "postgres"
	}
	if v, ok := raw["anonymous_role"]; !ok || v == nil {
		plain.AnonymousRole = "anon"
	}
	if v, ok := raw["db_pool"]; !ok || v == nil {
		plain.DbPool = 10.0
	}
	if 1000 < plain.DbPool {
		return fmt.Errorf("field %s: must be <= %v", "db_pool", 1000)
	}
	if 1 > plain.DbPool {
		return fmt.Errorf("field %s: must be >= %v", "db_pool", 1)
	}
	if v, ok := raw["db_pool_timeout"]; !ok || v == nil {
		plain.DbPoolTimeout = 10.0
	}
	if 1 > plain.DbPoolTimeout {
		return fmt.Errorf("field %s: must be >= %v", "db_pool_timeout", 1)
	}
	if v, ok := raw["db_schemas"]; !ok || v == nil {
		plain.DbSchemas = "public"
	}
	if plain.DbUri != nil {
		if matched, _ := regexp.MatchString(`^postgres(ql)?://.*`, string(*plain.DbUri)); !matched {
			return fmt.Errorf("field %s pattern match: must match %s", "DbUri", `^postgres(ql)?://.*`)
		}
	}
	if v, ok := raw["jwt_aud"]; !ok || v == nil {
		plain.JwtAud = ""
	}
	if v, ok := raw["jwt_secret_is_base64"]; !ok || v == nil {
		plain.JwtSecretIsBase64 = false
	}
	if v, ok := raw["log_level"]; !ok || v == nil {
		plain.LogLevel = "error"
	}
	if plain.MaxRows != nil && 1 > *plain.MaxRows {
		return fmt.Errorf("field %s: must be >= %v", "max_rows", 1)
	}
	if v, ok := raw["pre_request"]; !ok || v == nil {
		plain.PreRequest = ""
	}
	if v, ok := raw["role_claim_key"]; !ok || v == nil {
		plain.RoleClaimKey = "role"
	}
	if v, ok := raw["server_host"]; !ok || v == nil {
		plain.ServerHost = "0.0.0.0"
	}
	if v, ok := raw["server_port"]; !ok || v == nil {
		plain.ServerPort = 3000.0
	}
	if 65535 < plain.ServerPort {
		return fmt.Errorf("field %s: must be <= %v", "server_port", 65535)
	}
	if 1 > plain.ServerPort {
		return fmt.Errorf("field %s: must be >= %v", "server_port", 1)
	}
	if v, ok := raw["server_ssl_cert"]; !ok || v == nil {
		plain.ServerSslCert = ""
	}
	if v, ok := raw["server_ssl_key"]; !ok || v == nil {
		plain.ServerSslKey = ""
	}
	*j = PostgrestConf(plain)
	return nil
}

// WAL-G backup and archiving configuration
type WalgConf struct {
	// Azure storage account key
	AzAccountKey *string `json:"az_account_key,omitempty" yaml:"az_account_key,omitempty" mapstructure:"az_account_key,omitempty"`

	// Azure storage account name
	AzAccountName *string `json:"az_account_name,omitempty" yaml:"az_account_name,omitempty" mapstructure:"az_account_name,omitempty"`

	// Azure Storage prefix
	AzPrefix *string `json:"az_prefix,omitempty" yaml:"az_prefix,omitempty" mapstructure:"az_prefix,omitempty"`

	// Number of backups to retain
	BackupRetainCount int `json:"backup_retain_count,omitempty" yaml:"backup_retain_count,omitempty" mapstructure:"backup_retain_count,omitempty"`

	// Backup schedule in cron format
	BackupSchedule string `json:"backup_schedule,omitempty" yaml:"backup_schedule,omitempty" mapstructure:"backup_schedule,omitempty"`

	// Compression level (0-9)
	CompressionLevel int `json:"compression_level,omitempty" yaml:"compression_level,omitempty" mapstructure:"compression_level,omitempty"`

	// Compression method for backups
	CompressionMethod WalgConfCompressionMethod `json:"compression_method,omitempty" yaml:"compression_method,omitempty" mapstructure:"compression_method,omitempty"`

	// Maximum steps for delta backups
	DeltaMaxSteps int `json:"delta_max_steps,omitempty" yaml:"delta_max_steps,omitempty" mapstructure:"delta_max_steps,omitempty"`

	// Enable or disable WAL-G
	Enabled bool `json:"enabled,omitempty" yaml:"enabled,omitempty" mapstructure:"enabled,omitempty"`

	// Local file system prefix for backups
	FilePrefix *string `json:"file_prefix,omitempty" yaml:"file_prefix,omitempty" mapstructure:"file_prefix,omitempty"`

	// Google Cloud Storage prefix (e.g., gs://bucket/path/to/folder)
	GsPrefix *string `json:"gs_prefix,omitempty" yaml:"gs_prefix,omitempty" mapstructure:"gs_prefix,omitempty"`

	// Google Cloud project ID
	GsProjectId *string `json:"gs_project_id,omitempty" yaml:"gs_project_id,omitempty" mapstructure:"gs_project_id,omitempty"`

	// Google Cloud service account key JSON
	GsServiceAccountKey *string `json:"gs_service_account_key,omitempty" yaml:"gs_service_account_key,omitempty" mapstructure:"gs_service_account_key,omitempty"`

	// PostgreSQL data directory path
	PostgresqlDataDir string `json:"postgresql_data_dir,omitempty" yaml:"postgresql_data_dir,omitempty" mapstructure:"postgresql_data_dir,omitempty"`

	// AWS S3 access key ID
	S3AccessKey *string `json:"s3_access_key,omitempty" yaml:"s3_access_key,omitempty" mapstructure:"s3_access_key,omitempty"`

	// Custom S3 endpoint URL
	S3Endpoint *string `json:"s3_endpoint,omitempty" yaml:"s3_endpoint,omitempty" mapstructure:"s3_endpoint,omitempty"`

	// S3 storage prefix (e.g., s3://bucket/path/to/folder)
	S3Prefix *string `json:"s3_prefix,omitempty" yaml:"s3_prefix,omitempty" mapstructure:"s3_prefix,omitempty"`

	// AWS S3 region
	S3Region string `json:"s3_region,omitempty" yaml:"s3_region,omitempty" mapstructure:"s3_region,omitempty"`

	// AWS S3 secret access key
	S3SecretKey *string `json:"s3_secret_key,omitempty" yaml:"s3_secret_key,omitempty" mapstructure:"s3_secret_key,omitempty"`

	// AWS S3 session token (for temporary credentials)
	S3SessionToken *string `json:"s3_session_token,omitempty" yaml:"s3_session_token,omitempty" mapstructure:"s3_session_token,omitempty"`

	// Use SSL for S3 connections
	S3UseSsl bool `json:"s3_use_ssl,omitempty" yaml:"s3_use_ssl,omitempty" mapstructure:"s3_use_ssl,omitempty"`

	// Command to create WAL stream
	StreamCreateCommand *string `json:"stream_create_command,omitempty" yaml:"stream_create_command,omitempty" mapstructure:"stream_create_command,omitempty"`

	// Command to restore from WAL stream
	StreamRestoreCommand *string `json:"stream_restore_command,omitempty" yaml:"stream_restore_command,omitempty" mapstructure:"stream_restore_command,omitempty"`

	// Number of concurrent uploads
	UploadConcurrency int `json:"upload_concurrency,omitempty" yaml:"upload_concurrency,omitempty" mapstructure:"upload_concurrency,omitempty"`

	// Number of concurrent disk operations
	UploadDiskConcurrency int `json:"upload_disk_concurrency,omitempty" yaml:"upload_disk_concurrency,omitempty" mapstructure:"upload_disk_concurrency,omitempty"`

	// Verify WAL checksums during backup
	WalVerifyChecksum bool `json:"wal_verify_checksum,omitempty" yaml:"wal_verify_checksum,omitempty" mapstructure:"wal_verify_checksum,omitempty"`
}

type WalgConfCompressionMethod string

const WalgConfCompressionMethodBrotli WalgConfCompressionMethod = "brotli"
const WalgConfCompressionMethodLz4 WalgConfCompressionMethod = "lz4"
const WalgConfCompressionMethodLzma WalgConfCompressionMethod = "lzma"
const WalgConfCompressionMethodZstd WalgConfCompressionMethod = "zstd"

var enumValues_WalgConfCompressionMethod = []interface{}{
	"lz4",
	"lzma",
	"brotli",
	"zstd",
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *WalgConfCompressionMethod) UnmarshalJSON(value []byte) error {
	var v string
	if err := json.Unmarshal(value, &v); err != nil {
		return err
	}
	var ok bool
	for _, expected := range enumValues_WalgConfCompressionMethod {
		if reflect.DeepEqual(v, expected) {
			ok = true
			break
		}
	}
	if !ok {
		return fmt.Errorf("invalid value (expected one of %#v): %#v", enumValues_WalgConfCompressionMethod, v)
	}
	*j = WalgConfCompressionMethod(v)
	return nil
}

// UnmarshalJSON implements json.Unmarshaler.
func (j *WalgConf) UnmarshalJSON(value []byte) error {
	var raw map[string]interface{}
	if err := json.Unmarshal(value, &raw); err != nil {
		return err
	}
	type Plain WalgConf
	var plain Plain
	if err := json.Unmarshal(value, &plain); err != nil {
		return err
	}
	if v, ok := raw["backup_retain_count"]; !ok || v == nil {
		plain.BackupRetainCount = 7.0
	}
	if 1 > plain.BackupRetainCount {
		return fmt.Errorf("field %s: must be >= %v", "backup_retain_count", 1)
	}
	if v, ok := raw["backup_schedule"]; !ok || v == nil {
		plain.BackupSchedule = "0 2 * * *"
	}
	if v, ok := raw["compression_level"]; !ok || v == nil {
		plain.CompressionLevel = 1.0
	}
	if 9 < plain.CompressionLevel {
		return fmt.Errorf("field %s: must be <= %v", "compression_level", 9)
	}
	if 0 > plain.CompressionLevel {
		return fmt.Errorf("field %s: must be >= %v", "compression_level", 0)
	}
	if v, ok := raw["compression_method"]; !ok || v == nil {
		plain.CompressionMethod = "lz4"
	}
	if v, ok := raw["delta_max_steps"]; !ok || v == nil {
		plain.DeltaMaxSteps = 32.0
	}
	if 1 > plain.DeltaMaxSteps {
		return fmt.Errorf("field %s: must be >= %v", "delta_max_steps", 1)
	}
	if v, ok := raw["enabled"]; !ok || v == nil {
		plain.Enabled = false
	}
	if plain.GsPrefix != nil {
		if matched, _ := regexp.MatchString(`^gs://.*`, string(*plain.GsPrefix)); !matched {
			return fmt.Errorf("field %s pattern match: must match %s", "GsPrefix", `^gs://.*`)
		}
	}
	if v, ok := raw["postgresql_data_dir"]; !ok || v == nil {
		plain.PostgresqlDataDir = "/var/lib/postgresql/data"
	}
	if plain.S3Prefix != nil {
		if matched, _ := regexp.MatchString(`^s3://.*`, string(*plain.S3Prefix)); !matched {
			return fmt.Errorf("field %s pattern match: must match %s", "S3Prefix", `^s3://.*`)
		}
	}
	if v, ok := raw["s3_region"]; !ok || v == nil {
		plain.S3Region = "us-east-1"
	}
	if v, ok := raw["s3_use_ssl"]; !ok || v == nil {
		plain.S3UseSsl = true
	}
	if v, ok := raw["upload_concurrency"]; !ok || v == nil {
		plain.UploadConcurrency = 16.0
	}
	if 100 < plain.UploadConcurrency {
		return fmt.Errorf("field %s: must be <= %v", "upload_concurrency", 100)
	}
	if 1 > plain.UploadConcurrency {
		return fmt.Errorf("field %s: must be >= %v", "upload_concurrency", 1)
	}
	if v, ok := raw["upload_disk_concurrency"]; !ok || v == nil {
		plain.UploadDiskConcurrency = 1.0
	}
	if 100 < plain.UploadDiskConcurrency {
		return fmt.Errorf("field %s: must be <= %v", "upload_disk_concurrency", 100)
	}
	if 1 > plain.UploadDiskConcurrency {
		return fmt.Errorf("field %s: must be >= %v", "upload_disk_concurrency", 1)
	}
	if v, ok := raw["wal_verify_checksum"]; !ok || v == nil {
		plain.WalVerifyChecksum = true
	}
	*j = WalgConf(plain)
	return nil
}
